{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propogate Errors\n",
    "\n",
    "This notebook takes you through the steps of how to propogate errors for through the neural network model\n",
    "We use theano as a backend for Keras. Theano has a Jacobian function that allows for the calculation of the partial derivatives for the model, which is necessary for the error propogation. Your model must have also been trained using Theano\n",
    "\n",
    "* required packages: `numpy h5py keras theano matplotlib seaborn`\n",
    "* data files: \n",
    "    - starnet_cnn.h5\n",
    "    - mean_and_std.npy\n",
    "    - high_snr_test_data.h5\n",
    "    - apStar_combined_main.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = 'theano'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "datadir = '/home/ubuntu/starnet_data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtain data for normalizing labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_and_std = np.load(datadir + 'mean_and_std.npy')\n",
    "mean_labels = mean_and_std[0]\n",
    "std_labels = mean_and_std[1]\n",
    "num_labels = mean_and_std.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define function to denormalize labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize(lb_norm):\n",
    "    return ((lb_norm*std_labels) + mean_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load the high S/N test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(datadir + 'high_snr_test_data.h5', 'r') as F:\n",
    "    test_1_spectra = F[\"spectra\"][:]\n",
    "    test_1_spectra = test_1_spectra.reshape((test_1_spectra.shape[0],test_1_spectra.shape[1],1))\n",
    "    test_1_error_spectra = F[\"error_spectra\"][:]\n",
    "    test_1_labels = np.column_stack((F[\"TEFF\"][:],F[\"LOGG\"][:],F[\"FE_H\"][:]))\n",
    "print('Test set includes '+str(len(test_1_spectra))+' combined spectra.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict labels**\n",
    "\n",
    "Load a StarNet model and predict on the high S/N test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(datadir + 'starnet_cnn.h5')\n",
    "test_1_pred = denormalize(model.predict(test_1_spectra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load entire APOGEE dataset**\n",
    "\n",
    "This is necessary to obtain the an accurate assessment of the scatter between the model predictions and apogee labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(datadir + 'apStar_combined_main.h5', 'r') as F:\n",
    "    all_apogee_spectra = F['spectrum'][:]\n",
    "    all_apogee_labels = np.column_stack((F['TEFF'][:],F['LOGG'][:],F['FE_H'][:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize spectra**\n",
    "\n",
    "Again, same method as previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define edges of detectors\n",
    "blue_chip_begin = 322\n",
    "blue_chip_end = 3242\n",
    "green_chip_begin = 3648\n",
    "green_chip_end = 6048   \n",
    "red_chip_begin = 6412\n",
    "red_chip_end = 8306 \n",
    "\n",
    "# Separate spectra into chips\n",
    "\n",
    "blue_sp = all_apogee_spectra[:,blue_chip_begin:blue_chip_end]\n",
    "green_sp = all_apogee_spectra[:,green_chip_begin:green_chip_end]\n",
    "red_sp = all_apogee_spectra[:,red_chip_begin:red_chip_end]\n",
    "\n",
    "#Normalize spectra by chips\n",
    "\n",
    "blue_sp_med = np.median(blue_sp, axis=1)\n",
    "green_sp_med = np.median(green_sp, axis=1)\n",
    "red_sp_med = np.median(red_sp, axis=1)\n",
    "\n",
    "blue_sp = (blue_sp.T/blue_sp_med).T\n",
    "green_sp = (green_sp.T/green_sp_med).T\n",
    "red_sp = (red_sp.T/red_sp_med).T  \n",
    "\n",
    "# Recombine spectra\n",
    "\n",
    "all_apogee_spectra = np.column_stack((blue_sp,green_sp,red_sp))\n",
    "\n",
    "print('Large APOGEE dataset now contains '+str(all_apogee_spectra.shape[0])+' spectra, each with '+str(all_apogee_spectra.shape[1])+' wavelength bins')\n",
    "\n",
    "# Reshape spectra\n",
    "all_apogee_spectra = all_apogee_spectra.reshape((all_apogee_spectra.shape[0],all_apogee_spectra.shape[1],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make predictions on the fulle APOGEE dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_apogee_pred = denormalize(model.predict(all_apogee_spectra))\n",
    "all_apogee_resids = all_apogee_pred - all_apogee_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separate residuals into different bins**\n",
    "\n",
    "This is necessary to undestand how the scatter in different ranges of the label-space differs so that the appropriate scatter values are used when including the scatter in the error propogation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resid_t1 = all_apogee_resids[np.where((all_apogee_labels[:,0]<4000)&(all_apogee_labels[:,0]>10))[0]]\n",
    "resid_t2 = all_apogee_resids[np.where((all_apogee_labels[:,0]<4500)&(all_apogee_labels[:,0]>4000))[0]]\n",
    "resid_t3 = all_apogee_resids[np.where((all_apogee_labels[:,0]<4750)&(all_apogee_labels[:,0]>4500))[0]]\n",
    "resid_t4 = all_apogee_resids[np.where((all_apogee_labels[:,0]<5250)&(all_apogee_labels[:,0]>4750))[0]]\n",
    "resid_t5 = all_apogee_resids[np.where((all_apogee_labels[:,0]>5250))[0]]\n",
    "\n",
    "resid_l1 = all_apogee_resids[np.where((all_apogee_labels[:,1]<0.5)&(all_apogee_labels[:,1]>-10.))[0]]\n",
    "resid_l2 = all_apogee_resids[np.where((all_apogee_labels[:,1]<1.5)&(all_apogee_labels[:,1]>0.5))[0]]\n",
    "resid_l3 = all_apogee_resids[np.where((all_apogee_labels[:,1]<2.5)&(all_apogee_labels[:,1]>1.5))[0]]\n",
    "resid_l4 = all_apogee_resids[np.where((all_apogee_labels[:,1]<3.5)&(all_apogee_labels[:,1]>2.5))[0]]\n",
    "resid_l5 = all_apogee_resids[np.where((all_apogee_labels[:,1]>3.5))[0]]\n",
    "\n",
    "resid_f1 = all_apogee_resids[np.where((all_apogee_labels[:,2]<-1.3)&(all_apogee_labels[:,2]>-10.))[0]]\n",
    "resid_f2 = all_apogee_resids[np.where((all_apogee_labels[:,2]<-0.9)&(all_apogee_labels[:,2]>-1.3))[0]]\n",
    "resid_f3 = all_apogee_resids[np.where((all_apogee_labels[:,2]<-0.5)&(all_apogee_labels[:,2]>-0.9))[0]]\n",
    "resid_f4 = all_apogee_resids[np.where((all_apogee_labels[:,2]<-0.3)&(all_apogee_labels[:,2]>-0.5))[0]]\n",
    "resid_f5 = all_apogee_resids[np.where((all_apogee_labels[:,2]>-0.3))[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtain a random sample of residuals from each bin**\n",
    "\n",
    "Each sample has to be equal in size for proper statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(resid_t1)\n",
    "resid_t1 = resid_t1[0:1500]\n",
    "np.random.shuffle(resid_t2)\n",
    "resid_t2 = resid_t2[0:1500]\n",
    "np.random.shuffle(resid_t3)\n",
    "resid_t3 = resid_t3[0:1500]\n",
    "np.random.shuffle(resid_t4)\n",
    "resid_t4 = resid_t4[0:1500]\n",
    "np.random.shuffle(resid_t5)\n",
    "resid_t5 = resid_t5[0:1500]\n",
    "\n",
    "np.random.shuffle(resid_l1)\n",
    "resid_l1 = resid_l1[0:1500]\n",
    "np.random.shuffle(resid_l2)\n",
    "resid_l2 = resid_l2[0:1500]\n",
    "np.random.shuffle(resid_l3)\n",
    "resid_l3 = resid_l3[0:1500]\n",
    "np.random.shuffle(resid_l4)\n",
    "resid_l4 = resid_l4[0:1500]\n",
    "np.random.shuffle(resid_l5)\n",
    "resid_l5 = resid_l5[0:1500]\n",
    "\n",
    "np.random.shuffle(resid_f1)\n",
    "resid_f1 = resid_f1[0:1500]\n",
    "np.random.shuffle(resid_f2)\n",
    "resid_f2 = resid_f2[0:1500]\n",
    "np.random.shuffle(resid_f3)\n",
    "resid_f3 = resid_f3[0:1500]\n",
    "np.random.shuffle(resid_f4)\n",
    "resid_f4 = resid_f4[0:1500]\n",
    "np.random.shuffle(resid_f5)\n",
    "resid_f5 = resid_f5[0:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate scatter in different regions, $\\delta_{js}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_resid_t1 = np.std(resid_t1, axis=0)[0]\n",
    "std_resid_t2 = np.std(resid_t2, axis=0)[0]\n",
    "std_resid_t3 = np.std(resid_t3, axis=0)[0]\n",
    "std_resid_t4 = np.std(resid_t4, axis=0)[0]\n",
    "std_resid_t5 = np.std(resid_t5, axis=0)[0]\n",
    "\n",
    "std_resid_l1 = np.std(resid_l1, axis=0)[1]\n",
    "std_resid_l2 = np.std(resid_l2, axis=0)[1]\n",
    "std_resid_l3 = np.std(resid_l3, axis=0)[1]\n",
    "std_resid_l4 = np.std(resid_l4, axis=0)[1]\n",
    "std_resid_l5 = np.std(resid_l5, axis=0)[1]\n",
    "\n",
    "std_resid_f1 = np.std(resid_f1, axis=0)[2]\n",
    "std_resid_f2 = np.std(resid_f2, axis=0)[2]\n",
    "std_resid_f3 = np.std(resid_f3, axis=0)[2]\n",
    "std_resid_f4 = np.std(resid_f4, axis=0)[2]\n",
    "std_resid_f5 = np.std(resid_f5, axis=0)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a function that returns the Jacobian matrix**\n",
    "\n",
    "The jacobian matrix is a matrix of the first order derivatives of the outputs with respect to the input. In our case, this will be a 3-dimensional matrix with dimensions: (num_labels, num_test_spectra, num_flux_values).\n",
    "\n",
    "Each spectrum will therefore have 3 vectors the length of the spectrum: one vector for each of the first order derivatives of the output labels with respect to each flux value (wavelength bin)\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial h_{j}(\\textbf{x},\\textbf{W})}{\\partial \\textbf{x}} =  (\\frac{\\partial h_{j}(\\textbf{x},\\textbf{W})}{\\partial x_{1}},...,\\frac{\\partial h_{j}(\\textbf{x},\\textbf{W})}{\\partial x_{n}})\n",
    "\\end{equation} \n",
    "\n",
    "j = 1,...,3\n",
    "\n",
    "n = 1,...,7214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jac = theano.gradient.jacobian(denormalize(model.layers[-1].output).flatten(),wrt=model.layers[0].input)\n",
    "compute_jac = theano.function([model.layers[0].input],[jac],allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jacobian_matrix = np.zeros((3,1,7214))\n",
    "for i in range(len(test_1_spectra)):\n",
    "    a = compute_jac(test_1_spectra[i:i+1])[0].reshape(3,1,7214)\n",
    "    if i ==0:\n",
    "        jacobian_matrix = a\n",
    "    else:\n",
    "        jacobian_matrix = np.column_stack((jacobian_matrix,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mask extremely high values in the error spectra and nan values in Jacobian**\n",
    "\n",
    "The high values in the error spectrum are associated - for the most part - with zero-values in the APOGEE spectra. Since these zero values are essentially ignored in the model (due to RELU-activation and maxpooling layers) they do not effect the output labels and therefore, the flux errors associated with these zero-values give an innaccurate assessment of the prediction errors. If you were to include these error fluxes, you would have massive uncertainties in some of the stars' output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_1_error_spectra[test_1_error_spectra > 5] = 0\n",
    "jacobian_matrix = np.nan_to_num(jacobian_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine first order derivatives with error spectra**\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta_{j\\textbf{x}} = \\frac{\\partial h_{j}(\\textbf{x},\\textbf{W})}{\\partial \\textbf{x}} \\cdot \\Delta \\textbf{x}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_1_pred_errors = np.array((np.einsum('ij,ij->i', np.square(jacobian_matrix[0]), np.square(test_1_error_spectra)),np.einsum('ij,ij->i', np.square(jacobian_matrix[1]), np.square(test_1_error_spectra)),np.einsum('ij,ij->i', np.square(jacobian_matrix[2]), np.square(test_1_error_spectra)))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label names\n",
    "label_names = ['Teff  ','log(g)','[Fe/H]']\n",
    "units = ['K','cgs','dex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_err_sp = np.mean(np.sqrt(test_1_pred_errors), axis=0)\n",
    "print('Mean error due to error spectrum: \\n')\n",
    "for i, err in enumerate(mean_err_sp):\n",
    "      print(label_names[i]+':  '+\"{0:.3f}\".format(err)+' '+units[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine the previous errors with scatter from the corresponding bins**\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta h_{j} = \\sqrt{\\delta_{j\\textbf{x}}^{2}  + \\delta_{js}^{2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_1_total_err = np.zeros((len(test_1_pred),3))\n",
    "for i, label in enumerate(test_1_pred):\n",
    "    std_resid_temp = np.zeros((1,3))\n",
    "    if (label[0]<4000) & (label[0]>10):\n",
    "        std_resid_temp[0,0]=std_resid_t1\n",
    "    elif (label[0]<4500) & (label[0]>4000):\n",
    "        std_resid_temp[0,0]=std_resid_t2\n",
    "    elif (label[0]<4750) & (label[0]>4500):\n",
    "        std_resid_temp[0,0]=std_resid_t3\n",
    "    elif (label[0]<5250) & (label[0]>4750):\n",
    "        std_resid_temp[0,0]=std_resid_t4\n",
    "    elif (label[0]<10000) & (label[0]>5250):\n",
    "        std_resid_temp[0,0]=std_resid_t5\n",
    "        \n",
    "    if (label[1]<0.5) & (label[0]>-10):\n",
    "        std_resid_temp[0,1]=std_resid_l1\n",
    "    elif (label[1]<1.5) & (label[0]>0.5):\n",
    "        std_resid_temp[0,1]=std_resid_l2\n",
    "    elif (label[1]<2.5) & (label[0]>1.5):\n",
    "        std_resid_temp[0,1]=std_resid_l3\n",
    "    elif (label[1]<3.5) & (label[0]>2.5):\n",
    "        std_resid_temp[0,1]=std_resid_l4\n",
    "    elif (label[1]<100) & (label[0]>3.5):\n",
    "        std_resid_temp[0,1]=std_resid_l5\n",
    "    \n",
    "    if (label[2]<-1.3) & (label[0]>-10):\n",
    "        std_resid_temp[0,2]=std_resid_f1\n",
    "    elif (label[2]<-0.9) & (label[0]>-1.3):\n",
    "        std_resid_temp[0,2]=std_resid_f2\n",
    "    elif (label[2]<-0.5) & (label[0]>-0.9):\n",
    "        std_resid_temp[0,2]=std_resid_f3\n",
    "    elif (label[2]<-0.3) & (label[0]>-0.5):\n",
    "        std_resid_temp[0,2]=std_resid_f4\n",
    "    elif (label[2]<0.5) & (label[0]>-0.3):\n",
    "        std_resid_temp[0,2]=std_resid_f5\n",
    "    \n",
    "    test_1_total_err[i] = np.sqrt(test_1_pred_errors[i]+np.square(std_resid_temp))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_err_total = np.mean(test_1_total_err, axis=0)\n",
    "print('Mean total statistical errors: \\n')\n",
    "for i, err in enumerate(mean_err_total):\n",
    "      print(label_names[i]+':  '+\"{0:.3f}\".format(err)+' '+units[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
