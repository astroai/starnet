{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervized VAE StarNet\n",
    "\n",
    "\n",
    "* Inputs: APOGEE DR12 real spectra and simulated spectra with ASSET\n",
    "* Outputs: stellar parameters from ASSET\n",
    "\n",
    "This notebook goes through the building and training of two VAE models in series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import sys\n",
    "\n",
    "from keras.layers import (Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, Activation, \n",
    "                          Dropout, Conv1D, UpSampling1D, MaxPooling1D, ZeroPadding1D, LeakyReLU, AveragePooling1D)\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "import keras.initializers\n",
    "from keras_contrib.layers import InstanceNormalization\n",
    "\n",
    "plt.switch_backend('agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and normalization\n",
    "\n",
    "Some helper functions for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train_data_weighted_with_asset(data_file_l,data_file_u,indices_l=None,indices_u=None,\n",
    "                                       unlabeled=True,labeled=True):\n",
    "    # load APOGEE spectra\n",
    "    if unlabeled:\n",
    "        # Grab all\n",
    "        if indices_u is None:\n",
    "            with h5py.File(data_file_u,\"r\") as F:\n",
    "                ap_spectra = F['APOGEE spectrum'][:]\n",
    "                ap_err_spectra = F['APOGEE error_spectrum'][:]\n",
    "                ap_labels = np.column_stack((F['APOGEE TEFF'][:],F['APOGEE LOGG'][:],F['APOGEE FE_H'][:],\n",
    "                                            F['APOGEE alpha_M'][:],F['APOGEE N_M'][:],F['APOGEE C_M'][:]))\n",
    "        # Grab a batch\n",
    "        else:            \n",
    "            with h5py.File(data_file_u, \"r\") as F:\n",
    "                indices_bool = np.ones((len(F['APOGEE spectrum']),),dtype=bool)\n",
    "                indices_bool[:] = False\n",
    "                indices_bool[indices_u] = True \n",
    "\n",
    "                ap_spectra = F['APOGEE spectrum'][indices_bool,:]\n",
    "                ap_err_spectra = F['APOGEE error_spectrum'][indices_bool,:]\n",
    "                ap_labels = np.column_stack((F['APOGEE TEFF'][indices_bool],F['APOGEE LOGG'][indices_bool],\n",
    "                                         F['APOGEE FE_H'][indices_bool], F['APOGEE alpha_M'][indices_bool],\n",
    "                                         F['APOGEE N_M'][indices_bool],F['APOGEE C_M'][indices_bool]))\n",
    "    else:\n",
    "        ap_spectra=[]\n",
    "        ap_err_spectra=[]\n",
    "        ap_labels=[]\n",
    "        \n",
    "    # load ASSET spectra\n",
    "    if labeled:\n",
    "        # Grab all\n",
    "        if indices_l is None:\n",
    "            with h5py.File(data_file_l,\"r\") as F:    \n",
    "                synth_spectra = F['spectrum'][:]\n",
    "                synth_labels = np.column_stack((F['teff'][:],F['logg'][:],F['M_H'][:],\n",
    "                                                F['a_M'][:],F['N_M'][:],F['C_M'][:]))  \n",
    "                \n",
    "                bad_spectra = list(set(list(np.where(synth_spectra<0.)[0])))\n",
    "                for index in sorted(bad_spectra, reverse=True):\n",
    "                    del synth_spectra[index]\n",
    "                    del synth_labels[index]\n",
    "        # Grab a batch\n",
    "        else:\n",
    "            with h5py.File(data_file_l, \"r\") as F:\n",
    "                indices_bool = np.ones((len(F['spectrum']),),dtype=bool)\n",
    "                indices_bool[:] = False\n",
    "                indices_bool[indices_l] = True \n",
    "\n",
    "                synth_spectra = F['spectrum'][indices_bool,:]\n",
    "                synth_labels = np.column_stack((F['teff'][indices_bool],F['logg'][indices_bool],F['M_H'][indices_bool],\n",
    "                                                F['a_M'][indices_bool],F['N_M'][indices_bool],F['C_M'][indices_bool]))\n",
    "                \n",
    "                synth_spectra=list(synth_spectra)\n",
    "                synth_labels=list(synth_labels)\n",
    "                bad_spectra = list(set(list(np.where(synth_spectra<0.)[0])))\n",
    "                for index in sorted(bad_spectra, reverse=True):\n",
    "                    del synth_spectra[index]\n",
    "                    del synth_labels[index]\n",
    "                synth_spectra=np.array(synth_spectra)\n",
    "                synth_labels=np.array(synth_labels)\n",
    "    else:\n",
    "        synth_spectra=[]\n",
    "        synth_labels=[]\n",
    "\n",
    "    return ap_spectra,ap_err_spectra,ap_labels,synth_spectra,synth_labels\n",
    "\n",
    "# normalize label variables to have zero-mean and unit-variance\n",
    "def normalize(lb,mean_and_std_file='/data/stars/apogee/dr12/asset_labels_mean_and_std.npy'):\n",
    "    mean_and_std = np.load(mean_and_std_file)\n",
    "    return (lb-mean_and_std[0])/mean_and_std[1]\n",
    "\n",
    "def denormalize(lb_norm,mean_and_std_file='/data/stars/apogee/dr12/asset_labels_mean_and_std.npy'):\n",
    "    mean_and_std = np.load(mean_and_std_file)\n",
    "    return ((lb_norm*mean_and_std[1]) + mean_and_std[0])\n",
    "\n",
    "# normalize each spectrum to have zero-mean and unit-variance (ignore zero-values whe calculating mean and std)\n",
    "def normalize_spec(specs):\n",
    "    specs[specs == 0] = np.nan\n",
    "    mean_spec = np.nanmean(specs,axis=1).reshape(len(specs),1)\n",
    "    std_spec = np.nanstd(specs,axis=1).reshape(len(specs),1)\n",
    "    specs[np.isnan(specs)] = 0.\n",
    "    return (specs-mean_spec)/std_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for reshaping spectra into appropriate format for CNN\n",
    "def cnn_reshape(spectra):\n",
    "    return spectra.reshape(spectra.shape[0],spectra.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some model hyper-parameters\n",
    "\n",
    "img_cols, img_chns = 7214, 1  \n",
    "num_fluxes=7214\n",
    "input_shape=(num_fluxes,1)\n",
    "z_dims = 16\n",
    "num_labels=6\n",
    "batch_size = 64\n",
    "epsilon_std = 1.0\n",
    "learning_rate = 0.001\n",
    "decay = 0.0\n",
    "var_epsilon = 0.010\n",
    "\n",
    "padding=u'same'\n",
    "kernel_init = 'he_normal'\n",
    "bias_init = keras.initializers.Zeros()\n",
    "\n",
    "num_filters = [16, 16]\n",
    "filter_length = 3\n",
    "pool_length = 4\n",
    "num_hidden = [256,128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Augmentation\n",
    "\n",
    "\n",
    "In an effort to evenly distribute the weighting of the VAE, throughout training, a *zero-augmentation* technique was applied to the training spectra samples - both synthetic and observed. \n",
    "\n",
    "The zero-augmentation is implemented as the first layer in the encoder where a zero-augmentation mask is sent as an input along with the input spectrum and the two are multiplied together. \n",
    "\n",
    "The zero-augmentation mask is the same size as the input spectrum vector and is composed of ones and zeros. For the APOGEE wave-grid, the spectral region is divided into seven *chunks* and for each input spectrum a random 0-3 of these chunks are assigned to be zeros while the remainder of the zero-augmentation mask is made up of ones. This means for a given spectrum, the input for training may be 4/7ths, 5/7ths, 6/7ths, or the entire spectrum. This augmentation is done randomly throughout training, meaning that each spectrum will be randomly assigned a different zero-augmentation mask at every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zero-augmentation layer\n",
    "class ZeroAugmentLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(ZeroAugmentLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def zero_agument(self, x_real, zero_mask):\n",
    "        return x_real*zero_mask\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_real = inputs[0]\n",
    "        zero_mask = inputs[1]\n",
    "        x_augmented = self.zero_agument(x_real, zero_mask)\n",
    "\n",
    "        return x_augmented\n",
    "\n",
    "# a function for creating the zero-masks used during training\n",
    "def create_zero_mask(spectra,min_chunks,max_chunks,chunk_size,dataset=None,ones_padded=False):\n",
    "    if dataset is None:\n",
    "        zero_mask = np.ones_like(spectra)\n",
    "    elif dataset=='apogee':\n",
    "        zero_mask = np.ones((spectra.shape[0],7214))\n",
    "    elif dataset=='segue':\n",
    "        zero_mask = np.ones((spectra.shape[0],3688))\n",
    "    \n",
    "    num_spec = zero_mask.shape[0]\n",
    "    len_spec = zero_mask.shape[1]\n",
    "    num_bins = len_spec/chunk_size\n",
    "    remainder = len_spec%chunk_size\n",
    "    spec_sizes = np.array([chunk_size for i in range(num_bins)])\n",
    "    spec_sizes[-1]=spec_sizes[-1]+remainder\n",
    "    \n",
    "\n",
    "    num_bins_removed = np.random.randint(min_chunks,max_chunks+1,size=(num_spec,))\n",
    "    for i, mask in enumerate(zero_mask):\n",
    "        bin_indx_removed = np.random.choice(num_bins, num_bins_removed[i], replace=False)\n",
    "        for indx in bin_indx_removed:\n",
    "            if indx==0:\n",
    "                mask[indx*spec_sizes[indx]:(indx+1)*spec_sizes[indx]]=0.\n",
    "            else:\n",
    "                mask[indx*spec_sizes[indx-1]:indx*spec_sizes[indx-1]+spec_sizes[indx]]=0.\n",
    "\n",
    "    return zero_mask        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_trainable(model, train):\n",
    "    \"\"\"\n",
    "    Enable or disable training for the model\n",
    "    \"\"\"\n",
    "    model.trainable = train\n",
    "    for l in model.layers:\n",
    "        l.trainable = train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build encoder\n",
    "\n",
    "Takes spectra (x) and zero-augmentation mask as inputs and outputs latent distribution (z_mean and z_log_var). If the encoder is for the labeled data, the outputs will also include the stellar parameter distribution (y_mean and y_log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_encoder(input_spec,input_mask,labeled=False):\n",
    "    \n",
    "    # input conv layer with filter length 1, no bias value\n",
    "    #x = Conv1D(kernel_initializer=keras.initializers.Constant(0.5), activation='linear', padding=\"same\", filters=1, \n",
    "           #kernel_size=1,use_bias=False)(input_spec)\n",
    "    # instance normalize to bring each spectrum to zero-mean and unit variance\n",
    "    #spec_normed = InstanceNormalization()(input_spec)\n",
    "    \n",
    "    x = ZeroAugmentLayer()([input_spec,input_mask])\n",
    "    \n",
    "    # first conv layer\n",
    "    x = Conv1D(filters=num_filters[0], kernel_size=filter_length, strides=1, kernel_initializer=kernel_init,\n",
    "                   bias_initializer=bias_init, padding=padding)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    \n",
    "    # second conv layer\n",
    "    x = Conv1D(filters=num_filters[1], kernel_size=filter_length, strides=1, kernel_initializer=kernel_init,\n",
    "                   bias_initializer=bias_init, padding=padding)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    \n",
    "    # Avg pooling\n",
    "    x = AveragePooling1D(pool_size=pool_length)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # intermediate dense block\n",
    "    x = Dense(num_hidden[0], kernel_initializer=kernel_init)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # intermediate dense block\n",
    "    x = Dense(num_hidden[1], kernel_initializer=kernel_init)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # latent distribution output\n",
    "    z_mean = Dense(z_dims)(x)\n",
    "    z_log_var = Dense(z_dims)(x)\n",
    "    \n",
    "    if labeled:\n",
    "        # latent distribution output\n",
    "        y_mean = Dense(num_labels,name='y_mean')(x)\n",
    "        y_log_var = Dense(num_labels,name='y_log_var')(x)\n",
    "        \n",
    "        # return model as well as normalized spectra tensor\n",
    "        return Model([input_spec,input_mask],[z_mean,z_log_var,y_mean,y_log_var]),input_spec\n",
    "    else:\n",
    "        # return model as well as normalized spectra tensor\n",
    "        return Model([input_spec,input_mask],[z_mean,z_log_var]),input_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for obtaining a latent sample given a distribution\n",
    "def sampling(args, epsilon_std=epsilon_std):\n",
    "    z_mean, z_log_var = args\n",
    "    \n",
    "    epsilon = K.random_normal(shape=(K.int_shape(z_mean)[1],),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build decoder\n",
    "\n",
    "- if labeled input model: takes  z (latent variables) and y (stellar labels) concatenated into a single vector as an input and outputs a *normalized* stellar spectrum\n",
    "- if unlabeled input model: takes  z (latent variables) as an input and outputs a *normalized* stellar spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_decoder(input_zy):\n",
    "    \n",
    "    # input fully-connected block\n",
    "    x = Dense(num_hidden[1])(input_zy)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # upsampling fully-connected block\n",
    "    x = Dense(input_shape[0] * num_filters[1])(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # reshape for convolutional blocks\n",
    "    output_shape = (input_shape[0], num_filters[1],)\n",
    "    x = Reshape(output_shape)(x)\n",
    "\n",
    "    # first deconv block\n",
    "    x = Conv1D(kernel_initializer=kernel_init,bias_initializer=bias_init,padding=\"same\", \n",
    "                   filters=num_filters[1],kernel_size=filter_length)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    # second deconv block\n",
    "    x = Conv1D(kernel_initializer=kernel_init,bias_initializer=bias_init,padding=\"same\", \n",
    "                   filters=num_filters[0],kernel_size=filter_length)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    \n",
    "    # output conv layer\n",
    "    x = Conv1D(kernel_initializer=kernel_init,bias_initializer=bias_init,padding=\"same\", \n",
    "                   filters=1,kernel_size=filter_length,activation='linear')(x)\n",
    "\n",
    "    return Model(input_zy,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build VAE_A\n",
    "\n",
    "This model takes spectra (spec_A) as inputs, encodes (encoder_A) them into latent variables (z_A) and stellar labels (y_A) and then concatenates z_A and y_A into vector input for decoder_A that produces a spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder_A input placeholders\n",
    "input_spec_A = Input(shape=input_shape)\n",
    "input_mask_A = Input(shape=input_shape)\n",
    "\n",
    "# error_spectra_A placeholder\n",
    "input_err_spec_A = Input(shape=input_shape)\n",
    "\n",
    "# predictor_input_A placeholder\n",
    "input_z_A = Input(shape=(z_dims,))\n",
    "\n",
    "# decoder_input_A placeholder\n",
    "input_zy_A = Input(shape=(z_dims+num_labels,))\n",
    "\n",
    "# encoder model A\n",
    "encoder_A, normed_spec_A = build_encoder(input_spec_A, input_mask_A,labeled=True)\n",
    "\n",
    "# decoder model A\n",
    "decoder_A = build_decoder(input_zy_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build VAE_B\n",
    "\n",
    "This model takes spectra (spec_B) as inputs, encodes (encoder_B) them into latent variables (z_B), uses those latent variables as the input for decoder_B that produces a spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder_input_B placeholders\n",
    "input_spec_B = Input(shape=input_shape)\n",
    "input_mask_B = Input(shape=input_shape)\n",
    "\n",
    "# error_spectra_B placeholder\n",
    "input_err_spec_B = Input(shape=input_shape)\n",
    "\n",
    "# decoder_input_B placeholder\n",
    "input_z_B = Input(shape=(z_dims,))\n",
    "\n",
    "# encoder model B\n",
    "encoder_B, normed_spec_B = build_encoder(input_spec_B, input_mask_B)\n",
    "\n",
    "# decoder model B\n",
    "decoder_B = build_decoder(input_z_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create loss functions\n",
    "\n",
    "The VAEs have two loss functions that are minimized simultaneously:\n",
    "\n",
    "1. a weighted mean-squared-error to analyze the predicted spectra:\n",
    "\\begin{equation}\n",
    "mse = \\frac{1}{N}\\sum{\\frac{(x_{true}-x_{pred})^2}{(x_{err})^2}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "2. a relative entropy, KL (Kullback–Leibler divergence) loss to keep the latent variables within a similar distribuition:\n",
    "\\begin{equation}\n",
    "KL = \\frac{1}{N}\\sum{-\\frac{1}{2}(1.0+z_{log\\_var} - z_{avg}^2 - e^{z_{log\\_var}})}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE_Labeled_LossLayer_weighted(Layer):\n",
    "    __name__ = u'vae_labeled_loss_layer'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(VAE_Labeled_LossLayer_weighted, self).__init__(**kwargs)\n",
    "\n",
    "    def lossfun(self, x_true, x_pred, z_avg_1, z_log_var_1, z_avg_2, z_log_var_2,x_err,y_avg,y_log_var):\n",
    "        rec_loss = K.mean(K.square((x_true - x_pred)/x_err))\n",
    "        kl_loss_1 = K.mean(-0.5 * K.sum(1.0 + z_log_var_1 - K.square(z_avg_1) - K.exp(z_log_var_1), axis=-1))\n",
    "        kl_loss_2 = K.mean(-0.5 * K.sum(1.0 + z_log_var_2 - K.square(z_avg_2) - K.exp(z_log_var_2), axis=-1))\n",
    "        kl_loss_3 = K.mean(-0.5 * K.sum(1.0 + y_log_var - K.square(y_avg) - K.exp(y_log_var), axis=-1))\n",
    "        return rec_loss + kl_loss_1 +kl_loss_2\n",
    "        # not sure which one to use\n",
    "        #return rec_loss + kl_loss_1 +kl_loss_2+kl_loss_3\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_true = inputs[0]\n",
    "        x_pred = inputs[1]\n",
    "        x_err = inputs[2]\n",
    "        z_avg_1 = inputs[3]\n",
    "        z_log_var_1 = inputs[4]\n",
    "        z_avg_2 = inputs[5]\n",
    "        z_log_var_2 = inputs[6]\n",
    "        y_avg = inputs[7]\n",
    "        y_log_var = inputs[8]\n",
    "        loss = self.lossfun(x_true, x_pred, z_avg_1, z_log_var_1, z_avg_2, z_log_var_2, x_err, y_avg, y_log_var)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "\n",
    "        return x_true\n",
    "    \n",
    "class VAE_Unlabeled_LossLayer_weighted(Layer):\n",
    "    __name__ = u'vae_labeled_loss_layer'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(VAE_Unlabeled_LossLayer_weighted, self).__init__(**kwargs)\n",
    "\n",
    "    def lossfun(self, x_true, x_pred, z_avg_1, z_log_var_1, z_avg_2, z_log_var_2,x_err):\n",
    "        rec_loss = K.mean(K.square((x_true - x_pred)/x_err))\n",
    "        kl_loss_1 = K.mean(-0.5 * K.sum(1.0 + z_log_var_1 - K.square(z_avg_1) - K.exp(z_log_var_1), axis=-1))\n",
    "        kl_loss_2 = K.mean(-0.5 * K.sum(1.0 + z_log_var_2 - K.square(z_avg_2) - K.exp(z_log_var_2), axis=-1))\n",
    "        return rec_loss + kl_loss_1 +kl_loss_2\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_true = inputs[0]\n",
    "        x_pred = inputs[1]\n",
    "        x_err = inputs[2]\n",
    "        z_avg_1 = inputs[3]\n",
    "        z_log_var_1 = inputs[4]\n",
    "        z_avg_2 = inputs[5]\n",
    "        z_log_var_2 = inputs[6]\n",
    "        loss = self.lossfun(x_true, x_pred, z_avg_1, z_log_var_1, z_avg_2, z_log_var_2, x_err)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "\n",
    "        return x_true\n",
    "\n",
    "# dummy loss to give zeros, hence no gradients to train\n",
    "# the real loss is computed as the layer shown above and therefore this dummy loss is just \n",
    "# used to satisfy keras notation when compiling the model\n",
    "def zero_loss(y_true, y_pred):\n",
    "    return K.zeros_like(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeled process\n",
    "\n",
    "- input_spec_A: labeled spectra\n",
    "- input_mask_A: labeled zero-mask\n",
    "- input_y_l: known stellar labels \n",
    "    \n",
    "Process:\n",
    "    1. encode input_spec_A using encoder_A to produce latent distribution (z_mean_A_l, z_log_var_A_l) and stellar parameter distribution (y_mean_A_l, y_log_var_A_l)\n",
    "    2. sample from latent distribution to create a vector (z_A_l) of length z_dims\n",
    "    3. same for stellar parameter distribution\n",
    "    4. merge latent samples with stellar labels to create a vector (merged_zy_l) of length z_dims+num_labels \n",
    "    5. decode merged_zy_l using decoder_A into spectrum (output_spec_A_l)\n",
    "    6. encode output_spec_A_l using encoder_B to produce latent distribution (z_mean_B_l, z_log_var_B_l)\n",
    "    7. sample from latent distribution to create a vector (z_B_l) of length z_dims\n",
    "    8. decode z_B_l using decoder_B into spectrum (output_spec_B_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# outputs for encoder_A\n",
    "z_mean_A_l, z_log_var_A_l, y_mean_A_l, y_log_var_A_l = encoder_A([input_spec_A, input_mask_A])\n",
    "\n",
    "# loss for predictor\n",
    "def logy_loss(y, y_pred,y_log_var=y_log_var_A_l):\n",
    "    loss = (  0.5 * math.log(2 * math.pi)\n",
    "            + 0.5 * K.log(K.exp(y_log_var) + var_epsilon)\n",
    "            + 0.5 * K.square(y - y_pred) / (K.exp(y_log_var) + var_epsilon))\n",
    "    loss = num_labels*K.sum(loss, axis=-1)\n",
    "    return K.mean(loss)\n",
    "\n",
    "# sample from latent distribution given z_mean_A_l and z_log_var_A_l\n",
    "z_A_l = Lambda(sampling, output_shape=(z_dims,))([z_mean_A_l, z_log_var_A_l])\n",
    "y_A_l = Lambda(sampling, output_shape=(num_labels,))([y_mean_A_l, y_log_var_A_l])\n",
    "\n",
    "# labeled known stellar parameters input placeholder\n",
    "input_y_l = Input(shape=(num_labels,))\n",
    "\n",
    "# merge latent variables with known stellar labels\n",
    "merged_zy_l = concatenate([y_A_l, z_A_l])\n",
    "\n",
    "# decode latent variables and known stellar labels, input_y_l, into stellar spectrum\n",
    "output_spec_A_l = decoder_A(merged_zy_l)\n",
    "\n",
    "# encode produced spectrum output_spec_A_l using encoder B\n",
    "z_mean_B_l, z_log_var_B_l = encoder_B([output_spec_A_l, input_mask_A])\n",
    "\n",
    "# sample from latent distribution given z_mean_B_l and z_log_var_B_l\n",
    "z_B_l = Lambda(sampling, output_shape=(z_dims,))([z_mean_B_l, z_log_var_B_l])\n",
    "\n",
    "# decode latent variables, z_B_l, into stellar spectrum\n",
    "output_spec_B_l = decoder_B(z_B_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 7214, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 7214, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 [(None, 16), (None,  7426304     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 6)            0           model_1[1][2]                    \n",
      "                                                                 model_1[1][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16)           0           model_1[1][0]                    \n",
      "                                                                 model_1[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 22)           0           lambda_2[0][0]                   \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 7214, 1)      15356469    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 [(None, 16), (None,  7424756     model_2[1][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16)           0           model_3[1][0]                    \n",
      "                                                                 model_3[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 7214, 1)      15355701    lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 7214, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vae__labeled__loss_layer_weight [(None, 7214, 1), (N 0           input_1[0][0]                    \n",
      "                                                                 model_4[1][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 model_1[1][0]                    \n",
      "                                                                 model_1[1][1]                    \n",
      "                                                                 model_3[1][0]                    \n",
      "                                                                 model_3[1][1]                    \n",
      "                                                                 model_1[1][2]                    \n",
      "                                                                 model_1[1][3]                    \n",
      "==================================================================================================\n",
      "Total params: 45,563,230\n",
      "Trainable params: 45,099,486\n",
      "Non-trainable params: 463,744\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create loss layer that will evaluate:\n",
    "# 1. the normalized spectrum from the encoder_A input layer against \n",
    "#         the output normalized spectrum produced by decoder_B\n",
    "# 2. The two latent distributions using the KL loss\n",
    "vae_l_loss = VAE_Labeled_LossLayer_weighted()([normed_spec_A, output_spec_B_l, input_err_spec_A, z_mean_A_l, z_log_var_A_l, \n",
    "                                               z_mean_B_l, z_log_var_B_l, y_mean_A_l, y_log_var_A_l])\n",
    "\n",
    "# create model that takes labeled spectra, error spectra, zero-augmentation masks, and known stellar labels as inputs\n",
    "#      and outputs the above loss layer, as well as the predicted stellar parameters\n",
    "labeled_vae = Model(inputs=[input_spec_A, input_mask_A, input_err_spec_A, input_y_l], outputs=[vae_l_loss, y_mean_A_l])\n",
    "\n",
    "# compile model using zero-loss for the first output (loss already computed in loss layer)\n",
    "#      and a mean-squared-error to evaluate the predicted stellar labels\n",
    "labeled_vae.compile(loss=[zero_loss,logy_loss],\n",
    "                         optimizer=Adam(lr=1.0e-4, beta_1=0.5))\n",
    "\n",
    "labeled_vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unlabeled process\n",
    "\n",
    "\n",
    "First freeze y_mean and y_log_var model weights\n",
    " \n",
    "- input_spec_B: unlabeled spectra\n",
    "- input_mask_B: unlabeled zero-mask\n",
    "    \n",
    "Process:\n",
    "    1. encode input_spec_B using encoder_B to produce latent distribution (z_mean_B_u, z_log_var_B_u)\n",
    "    2. sample from latent distribution to create a vector (z_B_u) of length z_dims\n",
    "    3. decode z_B_u using decoder_B into spectrum (output_spec_B_u)\n",
    "    4. encode output_spec_B_u using encoder_A to produce latent distribution (z_mean_A_u, z_log_var_A_u) and stellar parameter distribution (y_mean_A_u, y_log_var_A_u)\n",
    "    5. sample from latent distribution to create a vector (z_A_u) of length z_dims\n",
    "    6. same for stellar parameter distribution\n",
    "    7. merge latent samples with predicted stellar labels to create a vector (merged_zy_u) of length z_dims+num_labels\n",
    "    8. decode merged_zy_u using decoder_A into spectrum (output_spec_A_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_A.get_layer('y_mean').trainable=False\n",
    "encoder_A.get_layer('y_log_var').trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# outputs for encoder_B\n",
    "z_mean_B_u, z_log_var_B_u = encoder_B([input_spec_B, input_mask_B])\n",
    "\n",
    "# sample from latent distribution given z_mean_B_u and z_log_var_B_u\n",
    "z_B_u = Lambda(sampling, output_shape=(z_dims,))([z_mean_B_u, z_log_var_B_u])\n",
    "\n",
    "# decode latent variables, z_B_u, into stellar spectrum\n",
    "output_spec_B_u = decoder_B(z_B_u)\n",
    "\n",
    "# encode output_spec_B_u with encoder_A\n",
    "z_mean_A_u, z_log_var_A_u, y_mean_A_u, y_log_var_A_u = encoder_A([output_spec_B_u, input_mask_B])\n",
    "\n",
    "# sample from latent distribution given z_mean_A_u and z_log_var_A_u\n",
    "z_A_u = Lambda(sampling, output_shape=(z_dims,))([z_mean_A_u, z_log_var_A_u])\n",
    "y_A_u = Lambda(sampling, output_shape=(z_dims,))([y_mean_A_u, y_log_var_A_u])\n",
    "\n",
    "# merge latent variables with predicted stellar labels\n",
    "merged_zy_u = concatenate([y_A_u, z_A_u])\n",
    "\n",
    "# decode latent variables and known stellar labels, input_y_u, into stellar spectrum\n",
    "output_spec_A_u = decoder_A(merged_zy_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 7214, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 7214, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 [(None, 16), (None,  7424756     input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 16)           0           model_3[2][0]                    \n",
      "                                                                 model_3[2][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 7214, 1)      15355701    lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 [(None, 16), (None,  7426304     model_4[2][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16)           0           model_1[2][2]                    \n",
      "                                                                 model_1[2][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16)           0           model_1[2][0]                    \n",
      "                                                                 model_1[2][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32)           0           lambda_6[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 7214, 1)      15356469    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 7214, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vae__unlabeled__loss_layer_weig [(None, 7214, 1), (N 0           input_6[0][0]                    \n",
      "                                                                 model_2[2][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[2][1]                    \n",
      "                                                                 model_3[2][0]                    \n",
      "                                                                 model_3[2][1]                    \n",
      "==================================================================================================\n",
      "Total params: 45,563,230\n",
      "Trainable params: 45,097,938\n",
      "Non-trainable params: 465,292\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create loss layer that will evaluate:\n",
    "# 1. the normalized spectrum from the encoder_B input layer against \n",
    "#         the output normalized spectrum produced by decoder_A\n",
    "# 2. The two (or three) latent distributions using the KL loss\n",
    "vae_u_loss = VAE_Unlabeled_LossLayer_weighted()([normed_spec_B, output_spec_A_u, input_err_spec_B, z_mean_A_u, z_log_var_A_u, \n",
    "                                               z_mean_B_u, z_log_var_B_u])\n",
    "\n",
    "\n",
    "# create model that takes unlabeled spectra, error spectra, and zero-augmentation masks as inputs\n",
    "#      and outputs the above loss layer\n",
    "unlabeled_vae = Model(inputs=[input_spec_B, input_mask_B, input_err_spec_B], outputs=[vae_u_loss])\n",
    "\n",
    "# compile model using zero-loss for the first output (loss already computed in loss layer)\n",
    "unlabeled_vae.compile(loss=[zero_loss],\n",
    "                         optimizer=Adam(lr=1.0e-4, beta_1=0.5))\n",
    "\n",
    "unlabeled_vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# models that encode and then decode spectra (this is used to plot the intermediate results during training)\n",
    "gen_x_to_x_l = Model([input_spec_A,input_mask_A,input_y_l], [normed_spec_A,output_spec_B_l])\n",
    "gen_x_to_x_l.compile(loss=['mse','mse'],\n",
    "                         optimizer=Adam(lr=1.0e-4, beta_1=0.5))\n",
    "\n",
    "gen_x_to_x_u = Model([input_spec_B,input_mask_B], [normed_spec_B,output_spec_A_u])\n",
    "gen_x_to_x_u.compile(loss=['mse','mse'],\n",
    "                         optimizer=Adam(lr=1.0e-4, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model that predicts stellar labels for unlabeled data \n",
    "# (this is used to make sure the error is generally decreasing throughout trainig)\n",
    "predictor_u = Model([input_spec_B,input_mask_B], y_mean_A_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_format(t):\n",
    "    m, s = divmod(t, 60)\n",
    "    m = int(m)\n",
    "    s = int(s)\n",
    "    if m == 0:\n",
    "        return u'%d sec' % s\n",
    "    else:\n",
    "        return u'%d min' % (m)\n",
    "\n",
    "# function for training\n",
    "def train_on_batch(x_obs,x_err_obs,x_synth,y_synth):    \n",
    "    \n",
    "    # add noise to synthetic data\n",
    "    noise_factor = 0.03\n",
    "    x_err_synth = noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_synth.shape)\n",
    "    x_err_synth[x_err_synth<0.005]=0.005\n",
    "    x_synth = x_synth + x_err_synth\n",
    "    \n",
    "    # normalize each spectrum to have zero-mean and unit variance\n",
    "    x_synth = normalize_spec(x_synth)\n",
    "    x_obs = normalize_spec(x_obs)\n",
    "    \n",
    "    # Labeled training\n",
    "    zero_mask = create_zero_mask(x_synth,\n",
    "                                          0,3,1030,dataset=None,ones_padded=False)\n",
    "    loss = labeled_vae.train_on_batch([cnn_reshape(x_synth),\n",
    "                                     cnn_reshape(zero_mask), cnn_reshape(x_err_synth), y_synth], \n",
    "                                    [cnn_reshape(x_synth), y_synth])\n",
    "\n",
    "    # Unlabeled training\n",
    "    zero_mask = create_zero_mask(x_obs,0,3,1030,dataset=None,ones_padded=False)\n",
    "    loss += [unlabeled_vae.train_on_batch([cnn_reshape(x_obs),\n",
    "                                           cnn_reshape(zero_mask),cnn_reshape(x_err_obs)],  \n",
    "                                          cnn_reshape(x_obs))]\n",
    "\n",
    "    losses = {'l_loss': loss[0],\n",
    "                 'l2_loss': loss[1],\n",
    "                 'p_loss': loss[2],\n",
    "                 'u_loss': loss[3],}\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model_name, data_file_l, data_file_u, epochs, reporter):\n",
    "    \n",
    "    # check to see how many spectra are in the unlabelled data file\n",
    "    with h5py.File(data_file_u, \"r\") as F:\n",
    "            num_data_ap = len(F['APOGEE spectrum'])\n",
    "            \n",
    "    # let's use 90% of the spectra\n",
    "    num_data_train_ap = int(num_data_ap*0.9)\n",
    "    test_indices_range_ap = [num_data_train_ap,num_data_ap]\n",
    "    \n",
    "    # check to see how many spectra are in the labelled data file\n",
    "    with h5py.File(data_file_l, \"r\") as F:\n",
    "            num_data_synth = len(F['spectrum'])\n",
    "            \n",
    "    # let's use 90% of the spectra\n",
    "    num_data_train_synth = int(num_data_synth*0.9)\n",
    "    test_indices_range_synth = [num_data_train_synth,num_data_synth]\n",
    "    \n",
    "    # load training spectra\n",
    "    ap_spectra, ap_err_spectra, ap_labels, synth_spectra, synth_labels = load_train_data_weighted_with_asset(data_file_l, data_file_u, indices_l=np.arange(0,num_data_train_synth), indices_u=np.arange(0,num_data_train_ap))\n",
    "        \n",
    "    # grab good labels from unlabeled dataset to compare predictions to throughout training\n",
    "    good_indices = np.where((ap_labels[:,0]!=-9999.)&(ap_labels[:,1]!=-9999.)&(ap_labels[:,2]!=-9999.)&\n",
    "                            (ap_labels[:,3]!=-9999.)&(ap_labels[:,4]!=-9999.)&(ap_labels[:,5]!=-9999.))[0]\n",
    "    \n",
    "    num_data_train_ap = len(ap_spectra)\n",
    "    perm_ap = np.random.permutation(num_data_train_ap)\n",
    "    \n",
    "\n",
    "    # loop through the number of epochs\n",
    "    for e in xrange(start_e,epochs):\n",
    "        \n",
    "        perm_synth = np.random.permutation(num_data_train_synth)        \n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # loop through the batches         \n",
    "        losses_=[]\n",
    "        for b in xrange(0, 200, batchsize): #num_data_train_synth         \n",
    "            \n",
    "            # check current batchsize\n",
    "            bsize = min(batchsize, num_data_train_synth - b)\n",
    "            indx_synth = perm_synth[b:b+bsize]\n",
    "            \n",
    "            \n",
    "            if len(perm_ap)<bsize:\n",
    "                perm_ap = np.random.permutation(num_data_train_ap)\n",
    "            indx_ap = perm_ap[0:bsize] \n",
    "            perm_ap = perm_ap[bsize:]\n",
    "               \n",
    "            # grab a batch of unlabeled data\n",
    "            x_obs = np.copy(ap_spectra[indx_ap])\n",
    "            x_err_obs = np.copy(ap_err_spectra[indx_ap])\n",
    "            \n",
    "            # grab a batch of labeled data\n",
    "            x_synth = np.copy(synth_spectra[indx_synth])\n",
    "            y_synth = np.copy(synth_labels[indx_synth])\n",
    "            \n",
    "            \n",
    "            # normalize stellar parameters\n",
    "            y_synth = normalize(y_synth)\n",
    "            \n",
    "            # train on batch\n",
    "            losses = train_on_batch(x_obs,x_err_obs,x_synth,y_synth)\n",
    "            \n",
    "            losses_.append(losses)\n",
    "            # Print current status\n",
    "            ratio = 100.0 * (b + bsize) / num_data_train_synth\n",
    "            print unichr(27) + u\"[2K\",; sys.stdout.write(u'')\n",
    "            print u'\\rEpoch #%d | %d / %d (%6.2f %%) ' %                   (e + 1, b + bsize, num_data_train_synth, ratio),; sys.stdout.write(u'')\n",
    "\n",
    "            for k in reporter:\n",
    "                if k in losses:\n",
    "                    print u'| %s = %5.3f ' % (k, losses[k]),; sys.stdout.write(u'')\n",
    "\n",
    "            # Compute ETA\n",
    "            elapsed_time = time.time() - start_time\n",
    "            eta = elapsed_time / (b + bsize) * (num_data_train_synth - (b + bsize))\n",
    "            print u'| ETA: %s ' % time_format(eta),; sys.stdout.write(u'')\n",
    "\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    \n",
    "   \n",
    "        print u''\n",
    "        \n",
    "        # Print epoch status\n",
    "        ratio = 100.0\n",
    "        print unichr(27) + u\"[2K\",; sys.stdout.write(u'')\n",
    "        print u'\\rEpoch #%d | %d / %d (%6.2f %%) ' %               (e + 1, num_data_train_synth, num_data_train_synth, ratio),; sys.stdout.write(u'')\n",
    "\n",
    "        losses_all = {}\n",
    "        for k in losses_[0].iterkeys():\n",
    "            losses_all[k] = tuple(d[k] for d in losses_)\n",
    "        for k in reporter:\n",
    "            if k in losses_all:\n",
    "                losses_all[k]=np.sum(losses_all[k])/len(losses_)\n",
    "        for k in reporter:\n",
    "            if k in losses_all:\n",
    "                print u'| %s = %5.3f ' % (k, losses_all[k]),; sys.stdout.write(u'')\n",
    "\n",
    "        # save losses to file to analyze throughout training        \n",
    "        myfile = open(model_name+'.txt', 'a')\n",
    "        for k in reporter:\n",
    "            if k in losses_all:\n",
    "                myfile.write(\"%s,\" % losses_all[k])\n",
    "        myfile.write(\"\\n\")\n",
    "        myfile.close()    \n",
    "        \n",
    "        \n",
    "        # compute mean-squared error on observed spec (compared against original pipeline)\n",
    "        sample_indices = np.random.choice(good_indices, 1000, replace=False)\n",
    "        samples = np.copy(ap_spectra[sample_indices])\n",
    "        samples = normalize_spec(samples) \n",
    "        mse = ((predictor_u.predict([cnn_reshape(samples),cnn_reshape(np.ones_like(samples))]) - normalize(ap_labels[sample_indices])) ** 2).mean(axis=None)\n",
    "        \n",
    "        # save mse on unlabeled data to analyze throughout training\n",
    "        myfile = open(model_name+'_mse.txt', 'a')\n",
    "        myfile.write(\"%s\" % mse)\n",
    "        myfile.write(\"\\n\")\n",
    "        myfile.close() \n",
    "   \n",
    "        # Compute Time Elapsed\n",
    "        elapsed_time = time.time() - start_time\n",
    "        eta = elapsed_time\n",
    "        print u'| TE: %s ' % time_format(eta),; sys.stdout.write(u'')\n",
    "\n",
    "        #sys.stdout.flush()\n",
    "        print('\\n')\n",
    "        \n",
    "        \n",
    "        # save models\n",
    "        encoder_A.save('models/encoder_A_'+model_name+'_epoch_'+str(e)+'.h5')\n",
    "        #predictor_A.save('models/predictor_A_'+model_name+'_epoch_'+str(e)+'.h5')\n",
    "        decoder_A.save('models/decoder_A_'+model_name+'_epoch_'+str(e)+'.h5')\n",
    "        encoder_B.save('models/encoder_B_'+model_name+'_epoch_'+str(e)+'.h5')\n",
    "        decoder_B.save('models/decoder_B_'+model_name+'_epoch_'+str(e)+'.h5')\n",
    "        \n",
    "        test_sample_indices = np.random.choice(range(test_indices_range_ap[0],test_indices_range_ap[1]), 5, replace=False)\n",
    "        sample_orig,_,_,_,_ = load_train_data_weighted_with_asset(data_file_l,data_file_u,indices_l=None,indices_u=test_sample_indices,\n",
    "                                       unlabeled=True,labeled=False)\n",
    "        zero_mask_test = create_zero_mask(sample_orig,0,3,1030)\n",
    "        sample_orig = normalize_spec(sample_orig)        \n",
    "        tex_x_normed,test_x = gen_x_to_x_u.predict([cnn_reshape(sample_orig),cnn_reshape(zero_mask_test)])\n",
    "        sample_orig = tex_x_normed.reshape(tex_x_normed.shape[0],tex_x_normed.shape[1])\n",
    "        sample_orig_aug = sample_orig*zero_mask_test\n",
    "        \n",
    "        sample_diff = sample_orig-test_x.reshape(test_x.shape[0],test_x.shape[1])\n",
    "\n",
    "        \n",
    "        #save test results\n",
    "        fig, axes = plt.subplots(20,1,figsize=(70, 20))\n",
    "        for i in range(len(test_sample_indices)):\n",
    "            axes[i*4].plot(sample_orig[i],c='r')\n",
    "            axes[i*4].set_ylim((-4.,4))\n",
    "            axes[1+4*i].plot(sample_orig_aug[i],c='g')\n",
    "            axes[1+4*i].set_ylim((-4.,4))\n",
    "            axes[2+4*i].plot(test_x[i],c='b')\n",
    "            axes[2+4*i].set_ylim((-4.,4))\n",
    "            axes[3+4*i].plot(sample_diff[i],c='m')\n",
    "            axes[3+4*i].set_ylim((-0.3,0.3))\n",
    "\n",
    "        plt.savefig('results/test_sample_ap_'+model_name+'_epoch_'+str(e)+'.jpg')\n",
    "        \n",
    "        \n",
    "        test_sample_indices = np.random.choice(range(test_indices_range_synth[0],test_indices_range_synth[1]), 5, replace=False)\n",
    "        _,_,_,sample_orig,sample_y = load_train_data_weighted_with_asset(data_file_l,data_file_u,indices_l=test_sample_indices,indices_u=None,\n",
    "                                       unlabeled=False,labeled=True)\n",
    "        zero_mask_test = create_zero_mask(sample_orig,0,3,1030)    \n",
    "        sample_orig = normalize_spec(sample_orig)        \n",
    "        tex_x_normed,test_x = gen_x_to_x_u.predict([cnn_reshape(sample_orig),cnn_reshape(zero_mask_test)])\n",
    "        sample_orig = tex_x_normed.reshape(tex_x_normed.shape[0],tex_x_normed.shape[1])\n",
    "        sample_orig_aug = sample_orig*zero_mask_test\n",
    "        \n",
    "        sample_diff = sample_orig-test_x.reshape(test_x.shape[0],test_x.shape[1])\n",
    "\n",
    "        \n",
    "        #save test results\n",
    "        fig, axes = plt.subplots(20,1,figsize=(70, 20))\n",
    "        for i in range(len(test_sample_indices)):\n",
    "            axes[i*4].plot(sample_orig[i],c='r')\n",
    "            axes[i*4].set_ylim((-4.,4))\n",
    "            axes[1+4*i].plot(sample_orig_aug[i],c='g')\n",
    "            axes[1+4*i].set_ylim((-4.,4))\n",
    "            axes[2+4*i].plot(test_x[i],c='b')\n",
    "            axes[2+4*i].set_ylim((-4.,4))\n",
    "            axes[3+4*i].plot(sample_diff[i],c='m')\n",
    "            axes[3+4*i].set_ylim((-0.3,0.3))\n",
    "\n",
    "        plt.savefig('results/test_sample_synth_'+model_name+'_epoch_'+str(e)+'.jpg')\n",
    "        \n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name='vae_ssl_cycle_test'\n",
    "start_e = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 | 256 / 316480 (  0.08 %)  | l_loss = 47678.082  | p_loss = 174.009  | u_loss = 54743.496  | ETA: 344 min \u001b[2K  \u001b[2K  \u001b[2K  \n",
      "Epoch #1 | 316480 / 316480 (100.00 %)  | l_loss = 50063.051  | p_loss = 197.928  | u_loss = 62352.875  | TE: 21 sec  \n",
      "\n",
      "Epoch #2 | 256 / 316480 (  0.08 %)  | l_loss = 44605.129  | p_loss = 216.749  | u_loss = 54097.461  | ETA: 341 min \u001b[2K  \u001b[2K  \u001b[2K  \n",
      "Epoch #2 | 316480 / 316480 (100.00 %)  | l_loss = 45513.855  | p_loss = 249.420  | u_loss = 55268.016  | TE: 21 sec  \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-dd621b8cb117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_file_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-b9cd5105b1d0>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model_name, data_file_l, data_file_u, epochs, reporter)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m#save test results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_orig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[1;32m   1177\u001b[0m     axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\n\u001b[1;32m   1178\u001b[0m                        \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplot_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplot_kw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m                        gridspec_kw=gridspec_kw)\n\u001b[0m\u001b[1;32m   1180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(self, nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 \u001b[0msubplot_kw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sharex\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_with\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msharex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0msubplot_kw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sharey\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_with\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msharey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                 \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msubplot_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0;31m# turn off redundant tick labeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/axes/_subplots.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# _axes_class is set in the subplot_class_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axes_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, axisbg, **kwargs)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# this call may differ for non-sep axes, e.g., polar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxisbg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfacecolor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             raise TypeError('Both axisbg and facecolor are not None. '\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_init_axis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYAxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_transScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/spines.pyc\u001b[0m in \u001b[0;36mregister_axis\u001b[0;34m(self, axis)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36mcla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_artist_props\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36mreset_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminorTicks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lastNumMajorTicks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lastNumMinorTicks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36m_get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   2095\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m             \u001b[0mtick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mYTick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axes, loc, label, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick1line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick1line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick2line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick2line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gridline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36m_get_tick2line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m                           \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                           \u001b[0mmarkeredgewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                           zorder=self._zorder)\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_yaxis_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tick2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_artist_props\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/lines.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dash_capstyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdash_capstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dash_joinstyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdash_joinstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_solid_capstyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolid_capstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_solid_joinstyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolid_joinstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/matplotlib/lines.pyc\u001b[0m in \u001b[0;36mset_solid_capstyle\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m   1405\u001b[0m             raise ValueError('set_solid_capstyle passed \"%s\";\\n' % (s,)\n\u001b[1;32m   1406\u001b[0m                              + 'valid capstyles are %s' % (self.validCap,))\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solidcapstyle\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solidcapstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f53fe7eac90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reporter=['l_loss','p_loss','u_loss']\n",
    "epochs=200\n",
    "batchsize=64\n",
    "if start_e>0:\n",
    "    start_e=start_e+1\n",
    "\n",
    "data_file_l = 'ASSET_lower_temp.h5'\n",
    "data_file_u = 'train_data.h5'\n",
    "\n",
    "\n",
    "fit_model(model_name,data_file_l, data_file_u, epochs,reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
