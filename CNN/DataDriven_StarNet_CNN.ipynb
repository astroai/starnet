{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Driven CNN StarNet\n",
    "\n",
    "This notebook builds a supervized learning model *StarNet* to predict stellar parameters from spectra, assuming we have access to a set of stellar parameters previously estimated.\n",
    "\n",
    "**Summary of the current implementation**\n",
    "- Inputs: APOGEE DR14 spectra\n",
    "- Labels: 3 stellar parameters resulting from the APOGEE pipeline\n",
    "- Model: See the build_model routine below\n",
    "\n",
    "**TODO**\n",
    "- could we add noise for spectra inputs also during training?\n",
    "- add stellar abundances as parameters \n",
    "- follow the recipe for errors on parameters (better than dropout?): https://tech.instacart.com/3-nips-papers-we-loved-befb39a75ec2\n",
    "- compare with the Bayesian NN from Henry: http://astronn.readthedocs.io/en/latest/neuralnets/apogee_bcnn.html\n",
    "- compare normalization procedures: - ASPCAP, The Cannon, simplescaler and including in the CNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout, Input\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "from keras_contrib.layers import InstanceNormalization\n",
    "from keras.layers import RepeatVector,Add\n",
    "from keras.layers import UpSampling2D, Reshape, Activation\n",
    "from keras.models import Model\n",
    "import keras.initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameters for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# activation function used following every layer except for the output layers\n",
    "activation = 'relu'\n",
    "\n",
    "# model weight initializer\n",
    "initializer = 'he_normal'\n",
    "\n",
    "num_fluxes = 7514\n",
    "num_labels = 3\n",
    "\n",
    "# shape of input spectra that is fed into the input layer\n",
    "input_shape = (None,num_fluxes,1)\n",
    "\n",
    "# number of filters used in the convolutional layers\n",
    "num_filters = 8\n",
    "\n",
    "# length of the filters in the convolutional layers\n",
    "filter_length = 3\n",
    "\n",
    "# length of the maxpooling window \n",
    "pool_length = 4\n",
    "\n",
    "# number of nodes in each of the hidden fully connected layers\n",
    "num_hidden = [256,128]\n",
    "\n",
    "# number of spectra fed into model at once during training\n",
    "batch_size = 64\n",
    "\n",
    "# maximum number of interations for model training\n",
    "max_epochs = 30\n",
    "\n",
    "# initial learning rate for optimization algorithm\n",
    "lr = 0.0001\n",
    "    \n",
    "# exponential decay rate for the 1st moment estimates for optimization algorithm\n",
    "beta_1 = 0.9\n",
    "\n",
    "# exponential decay rate for the 2nd moment estimates for optimization algorithm\n",
    "beta_2 = 0.999\n",
    "\n",
    "# a small constant for numerical stability for optimization algorithm\n",
    "optimizer_epsilon = 1e-08\n",
    "\n",
    "early_stopping_min_delta = 0.0001\n",
    "early_stopping_patience = 4\n",
    "reduce_lr_factor = 0.5\n",
    "reuce_lr_epsilon = 0.0009\n",
    "reduce_lr_patience = 2\n",
    "reduce_lr_min = 0.00008\n",
    "loss_function = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_spec):\n",
    "\n",
    "    # input conv layer with filter length 1, no bias value\n",
    "    x = Conv1D(kernel_initializer=keras.initializers.Constant(0.5),\n",
    "               activation='linear', padding=\"same\", filters=1,\n",
    "               kernel_size=1,use_bias=False)(input_spec)\n",
    "    \n",
    "    # instance normalize to bring each spectrum to zero-mean and unit variance\n",
    "    normed_spec = InstanceNormalization()(x)\n",
    "    \n",
    "    # upsample the spectra so that they can be easily added to the output of the conv blocks\n",
    "    # this method just repeats the spectra n=num_filters times\n",
    "    normed_spec = Reshape((num_fluxes,1,1))(normed_spec)\n",
    "    repeated_spec = UpSampling2D(size=(1, num_filters))(normed_spec)\n",
    "    \n",
    "    # reshape spectra and repeated spectra to proper shape for 1D Conv layers\n",
    "    repeated_spec = Reshape((num_fluxes,num_filters))(repeated_spec)    \n",
    "    x = Reshape((num_fluxes,1))(normed_spec)\n",
    "    \n",
    "    # Conv block w/ InstanceNorm w/ dropout\n",
    "    x = Conv1D(kernel_initializer=initializer, padding=\"same\", filters=num_filters, \n",
    "               kernel_size=filter_length)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = Conv1D(kernel_initializer=initializer, padding=\"same\", filters=num_filters, \n",
    "               kernel_size=filter_length)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = Add()([x, repeated_spec])\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Conv block w/ InstanceNorm w/o dropout\n",
    "    x = Conv1D(kernel_initializer=initializer, padding=\"same\", filters=num_filters, \n",
    "               kernel_size=filter_length)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = Conv1D(kernel_initializer=initializer, padding=\"same\", filters=num_filters, \n",
    "               kernel_size=filter_length)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = Add()([x, repeated_spec])\n",
    "\n",
    "    # Avg pooling w/ dropout (DO NOT APPLY DROPOUT BEFORE POOLING)\n",
    "    x = AveragePooling1D(pool_size=pool_length)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Fully connected blocks w/ BatchNorm\n",
    "    x = Dense(num_hidden[0], kernel_initializer=initializer)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Dense(num_hidden[1], kernel_initializer=initializer)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # output nodes\n",
    "    output_pred = Dense(units=num_labels, activation=\"linear\")(x)\n",
    "\n",
    "    return Model(input_spec,output_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 7514, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 7514, 1)      1           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_1 (Insta (None, 7514, 1)      2           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 7514, 1, 1)   0           instance_normalization_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 7514, 1)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 7514, 8)      32          reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 7514, 8)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_2 (Insta (None, 7514, 8)      2           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 7514, 8)      200         instance_normalization_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 7514, 8)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 7514, 8, 1)   0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_3 (Insta (None, 7514, 8)      2           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 7514, 8)      0           up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7514, 8)      0           instance_normalization_3[0][0]   \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7514, 8)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 7514, 8)      200         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 7514, 8)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_4 (Insta (None, 7514, 8)      2           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 7514, 8)      200         instance_normalization_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 7514, 8)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_5 (Insta (None, 7514, 8)      2           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7514, 8)      0           instance_normalization_5[0][0]   \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_1 (AveragePoo (None, 1878, 8)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1878, 8)      0           average_pooling1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 15024)        0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          3846400     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            387         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,881,862\n",
      "Trainable params: 3,881,094\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_spec = Input(shape=(num_fluxes,1,))\n",
    "model = build_model(input_spec)\n",
    "optimizer = Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=optimizer_epsilon, decay=0.0)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=early_stopping_min_delta, \n",
    "                               patience=early_stopping_patience, verbose=2, mode='min')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, epsilon=reuce_lr_epsilon, \n",
    "                              patience=reduce_lr_patience, min_lr=reduce_lr_min, mode='min', verbose=2)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load non-normalized spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference set includes 89554 individual visit spectra.\n",
      "Each spectrum contains 7514 wavelength bins\n",
      "Training set includes 80598 spectra and the cross-validation set includes 8784 spectra\n"
     ]
    }
   ],
   "source": [
    "# hack to load pre-computed mean and std-dev for faster normalization\n",
    "mean_and_std = np.load('/data/stars/apogee/dr14/aspcap_labels_mean_and_std.npy')\n",
    "mean_labels = mean_and_std[0]\n",
    "std_labels = mean_and_std[1]\n",
    "num_labels = mean_and_std.shape[1]\n",
    "\n",
    "def normalize(lb):\n",
    "    return (lb-mean_labels)/std_labels\n",
    "\n",
    "data_file = '/data/stars/apogee/dr14/starnet_training_data.h5'\n",
    "\n",
    "with h5py.File(data_file,\"r\") as F:\n",
    "    spectra = F[\"spectrum\"][:]\n",
    "    labels = np.column_stack((F[\"TEFF\"][:],F[\"LOGG\"][:],F[\"FE_H\"][:]))\n",
    "    # Normalize labels\n",
    "    labels = normalize(labels)\n",
    "print('Reference set includes '+str(len(spectra))+' individual visit spectra.')\n",
    "\n",
    "# define the number of wavelength bins (typically 7214)\n",
    "num_fluxes = spectra.shape[1]\n",
    "print('Each spectrum contains '+str(num_fluxes)+' wavelength bins')\n",
    "\n",
    "num_train=int(0.9*len(labels))\n",
    "\n",
    "# set NaN values to zero\n",
    "indices_nan = np.where(np.isnan(spectra))\n",
    "spectra[indices_nan]=0.\n",
    "\n",
    "# some visit spectra are just zero-vectors... remove these.\n",
    "spec_std = np.std(spectra,axis=1)\n",
    "spec_std = spec_std.reshape(spec_std.shape[0],1)\n",
    "indices = np.where(spec_std!=0.)[0]\n",
    "spectra = spectra[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "reference_data = np.column_stack((spectra,labels))\n",
    "np.random.shuffle(reference_data)\n",
    "\n",
    "train_spectra = reference_data[0:num_train,0:num_fluxes]\n",
    "\n",
    "# Reshape spectra for convolutional layers\n",
    "train_spectra = train_spectra.reshape(train_spectra.shape[0], train_spectra.shape[1], 1)\n",
    "train_labels = reference_data[0:num_train,num_fluxes:]\n",
    "\n",
    "cv_spectra = reference_data[num_train:,0:num_fluxes]\n",
    "cv_spectra = cv_spectra.reshape(cv_spectra.shape[0], cv_spectra.shape[1], 1)\n",
    "cv_labels = reference_data[num_train:,num_fluxes:]\n",
    "\n",
    "reference_data=[]\n",
    "spectra=[]\n",
    "labels=[]\n",
    "\n",
    "print('Training set includes '+str(len(train_spectra))+' spectra and the cross-validation set includes '+str(len(cv_spectra))+' spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80598 samples, validate on 8784 samples\n",
      "Epoch 1/30\n",
      " - 1722s - loss: 0.6490 - val_loss: 0.0766\n",
      "Epoch 2/30\n",
      " - 1743s - loss: 0.3082 - val_loss: 0.0539\n",
      "Epoch 3/30\n",
      " - 1745s - loss: 0.1925 - val_loss: 0.0336\n",
      "Epoch 4/30\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "\n",
    "# Train model \n",
    "model.fit(train_spectra, train_labels, validation_data=(cv_spectra, cv_labels),\n",
    "          epochs=max_epochs, batch_size=batch_size, verbose=2,\n",
    "          callbacks=[reduce_lr,early_stopping])\n",
    "\n",
    "time2 = time.time()\n",
    "\n",
    "print(\"\\n\" + str(time2-time1) + \" seconds for training\\n\")\n",
    "\n",
    "# Save model in current directory\n",
    "model.save('StarNet_DR14.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spectra Normalization\n",
    "\n",
    "Tentative to replace what stellar spectroscopist call normalization (supression of a global continuum over the whole spectrum) with an input normalization.\n",
    "\n",
    "This test is simply a convolutional layer with one filter of length 1, followed by an InstanceNormalization layer\n",
    "\n",
    "First build a model that only includes our input convolutional and instance normalization layers. \n",
    "\n",
    "**Note:** I use a constant initialization of 0.5 because if the kernel is < 0. then the normalized spectra are inverted. this probably doesn't matter for the NN but it makes it a lot nicer to plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_normalizer_model(input_spec):\n",
    "\n",
    "    # input conv layer with filter length 1 to flatten the shape\n",
    "    x = Conv1D(kernel_initializer=keras.initializers.Constant(0.5), activation='linear', padding=\"same\", filters=1, \n",
    "           kernel_size=1,use_bias=False)(input_spec)\n",
    "    # instance normalize to bring each spectrum to zero-mean and unit variance\n",
    "    normed_spec = InstanceNormalization()(x)\n",
    "    \n",
    "    return Model(input_spec,normed_spec) \n",
    "\n",
    "input_spec = Input(shape=(num_fluxes,1,))\n",
    "model = build_normalizer_model(input_spec)\n",
    "model.summary()\n",
    "normalized_cv = model.predict(cv_spectra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the input spectra, then the normalized spectra. I will force the second of the two plots to have the same y-axis range to ensure that the range for our normalized spectra are similar to one another "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for i in range(10):\n",
    "    fig, axes = plt.subplots(2,1,figsize=(70, 10))\n",
    "    axes[0].plot(cv_spectra[i,:,0],c='b')\n",
    "    axes[1].plot(normalized_cv[i,:,0],c='r')\n",
    "    axes[1].set_ylim((-4,4))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to do some pre-processing clipping to the spectra to elminate the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "Is the stacking method used on spectra to add them to the output from conv blocks correct?\n",
    "\n",
    "First extend previous model to include the upsample layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_upsample_model(input_spec):\n",
    "\n",
    "    # input conv layer with filter length 1, no bias value\n",
    "    x = Conv1D(kernel_initializer=keras.initializers.Constant(0.5), activation='linear', padding=\"same\", filters=1, \n",
    "           kernel_size=1,use_bias=False)(input_spec)\n",
    "    # instance normalize to bring each spectrum to zero-mean and unit variance\n",
    "    normed_spec = InstanceNormalization()(x)\n",
    "    \n",
    "    # upsample the spectra so that they can be easily added to the output of the conv layers\n",
    "    # this method just repeats the spectra n=num_filters times\n",
    "    normed_spec = Reshape((num_fluxes,1,1))(normed_spec)\n",
    "    repeated_spec = UpSampling2D(size=(1, num_filters))(normed_spec)\n",
    "    repeated_spec = Reshape((num_fluxes,num_filters))(repeated_spec)\n",
    "    \n",
    "    return Model(input_spec,repeated_spec) \n",
    "\n",
    "input_spec = Input(shape=(num_fluxes,1,))\n",
    "model = build_upsample_model(input_spec)\n",
    "model.summary()\n",
    "upsampled_cv = model.predict(cv_spectra[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the input spectra, then the normalized upsampled spectra\n",
    "for i in range(5):\n",
    "    fig, axes = plt.subplots(9,1,figsize=(70, 10))\n",
    "    axes[0].plot(cv_spectra[i,:,0],c='b')\n",
    "    for ii in range(8):\n",
    "        axes[ii+1].plot(upsampled_cv[i,:,ii],c='r')\n",
    "        axes[ii+1].set_ylim((-4,4))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
