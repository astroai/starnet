{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propogate Errors\n",
    "\n",
    "## THEANO BACKEND ONLY\n",
    "\n",
    "## This notebook takes you through the steps of how to propogate errors for through the neural network model\n",
    "\n",
    "## required packages:\n",
    "- numpy\n",
    "- h5py\n",
    "- Keras \n",
    "  - must be using the same version used to train the model\n",
    "- Theano \n",
    "  - backend for Keras, Theano has a Jacobian function that allows for the calculation of the partial derivatives for the model, which is necessary for the error propogation. Your model must have also been trained using Theano\n",
    "- Matplotlib and seaborn are only necessary to make plots of predictions vs. ASPCAP Dr12 labels\n",
    "\n",
    "## required data files:\n",
    "- model file\n",
    "  - can be created in $4\\_Train\\_Model\\_Keras\\_2.ipynb$ or $4\\_Train\\_Model\\_Keras\\_2.ipynb$\n",
    "- test set file\n",
    "  - can be created in $3\\_Preprocessing\\_of\\_Test\\_Data.ipynb$ or downloaded  in $1\\_Download\\_Data.ipynb$\n",
    "- mean_and_std.npy\n",
    "  - can be created in $3\\_Preprocessing\\_of\\_Test\\_Data.ipynb$ or downloaded in $1\\_Download\\_Data.ipynb$\n",
    "- apStar_combined_main.h5\n",
    "  - can be downloaded in $1\\_Download\\_Data.ipynb$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = 'theano'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain data for normalizing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_and_std = np.load('mean_and_std.npy')\n",
    "mean_labels = mean_and_std[0]\n",
    "std_labels = mean_and_std[1]\n",
    "num_labels = mean_and_std.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to denormalize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize(lb_norm):\n",
    "    return ((lb_norm*std_labels)+mean_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savename = 'high_snr_test_data.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set includes 2780 combined spectra.\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(savename,\"r\") as F:\n",
    "    test_1_spectra = F[\"spectra\"][:]\n",
    "    test_1_spectra = test_1_spectra.reshape((test_1_spectra.shape[0],test_1_spectra.shape[1],1))\n",
    "    test_1_error_spectra = F[\"error_spectra\"][:]\n",
    "    test_1_labels = np.column_stack((F[\"TEFF\"][:],F[\"LOGG\"][:],F[\"FE_H\"][:]))\n",
    "print('Test set includes '+str(len(test_1_spectra))+' combined spectra.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Theano_Keras_1.h5 loaded.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Model_Theano_Keras_1.h5'\n",
    "model = load_model(model_name)\n",
    "print(model_name+' loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_1_pred = denormalize(model.predict(test_1_spectra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load entire APOGEE dataset\n",
    "This is necessary to obtain the an accurate assessment of the scatter between the model predictions and apogee labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savename = '/data/stars/teaghan/apStar_combined_main.h5'\n",
    "with h5py.File(savename,\"r\") as F:\n",
    "    all_apogee_spectra = F[\"spectrum\"][:]\n",
    "    all_apogee_labels = np.column_stack((F[\"TEFF\"][:],F[\"LOGG\"][:],F[\"FE_H\"][:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize spectra\n",
    "same method as was used in  $2\\_Preprocessing\\_of\\_Training\\_Data.ipynb$ and $3\\_Preprocessing\\_of\\_Test\\_Data.ipynb$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large APOGEE dataset now contains 147590 spectra, each with 7214 wavelength bins\n"
     ]
    }
   ],
   "source": [
    "# Define edges of detectors\n",
    "blue_chip_begin = 322\n",
    "blue_chip_end = 3242\n",
    "green_chip_begin = 3648\n",
    "green_chip_end = 6048   \n",
    "red_chip_begin = 6412\n",
    "red_chip_end = 8306 \n",
    "\n",
    "# Separate spectra into chips\n",
    "\n",
    "blue_sp = all_apogee_spectra[:,blue_chip_begin:blue_chip_end]\n",
    "green_sp = all_apogee_spectra[:,green_chip_begin:green_chip_end]\n",
    "red_sp = all_apogee_spectra[:,red_chip_begin:red_chip_end]\n",
    "\n",
    "#Normalize spectra by chips\n",
    "\n",
    "blue_sp_med = np.median(blue_sp, axis=1)\n",
    "green_sp_med = np.median(green_sp, axis=1)\n",
    "red_sp_med = np.median(red_sp, axis=1)\n",
    "\n",
    "blue_sp = (blue_sp.T/blue_sp_med).T\n",
    "green_sp = (green_sp.T/green_sp_med).T\n",
    "red_sp = (red_sp.T/red_sp_med).T  \n",
    "\n",
    "# Recombine spectra\n",
    "\n",
    "all_apogee_spectra = np.column_stack((blue_sp,green_sp,red_sp))\n",
    "\n",
    "print('Large APOGEE dataset now contains '+str(all_apogee_spectra.shape[0])+' spectra, each with '+str(all_apogee_spectra.shape[1])+' wavelength bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshape spectra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_apogee_spectra = all_apogee_spectra.reshape((all_apogee_spectra.shape[0],all_apogee_spectra.shape[1],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make predictions on large APOGEE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_apogee_pred = denormalize(model.predict(all_apogee_spectra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_apogee_diffs = all_apogee_pred-all_apogee_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate residuals into different bins\n",
    "This is necessary to undestand how the scatter in different ranges of the label-space differs so that the appropriate scatter values are used when including the scatter in the error propogation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_t1 = all_apogee_diffs[np.where((all_apogee_labels[:,0]<4000)&(all_apogee_labels[:,0]>10))[0]]\n",
    "diff_t2 = all_apogee_diffs[np.where((all_apogee_labels[:,0]<4500)&(all_apogee_labels[:,0]>4000))[0]]\n",
    "diff_t3 = all_apogee_diffs[np.where((all_apogee_labels[:,0]<4750)&(all_apogee_labels[:,0]>4500))[0]]\n",
    "diff_t4 = all_apogee_diffs[np.where((all_apogee_labels[:,0]<5250)&(all_apogee_labels[:,0]>4750))[0]]\n",
    "diff_t5 = all_apogee_diffs[np.where((all_apogee_labels[:,0]>5250))[0]]\n",
    "\n",
    "diff_l1 = all_apogee_diffs[np.where((all_apogee_labels[:,1]<0.5)&(all_apogee_labels[:,1]>-10.))[0]]\n",
    "diff_l2 = all_apogee_diffs[np.where((all_apogee_labels[:,1]<1.5)&(all_apogee_labels[:,1]>0.5))[0]]\n",
    "diff_l3 = all_apogee_diffs[np.where((all_apogee_labels[:,1]<2.5)&(all_apogee_labels[:,1]>1.5))[0]]\n",
    "diff_l4 = all_apogee_diffs[np.where((all_apogee_labels[:,1]<3.5)&(all_apogee_labels[:,1]>2.5))[0]]\n",
    "diff_l5 = all_apogee_diffs[np.where((all_apogee_labels[:,1]>3.5))[0]]\n",
    "\n",
    "diff_f1 = all_apogee_diffs[np.where((all_apogee_labels[:,2]<-1.3)&(all_apogee_labels[:,2]>-10.))[0]]\n",
    "diff_f2 = all_apogee_diffs[np.where((all_apogee_labels[:,2]<-0.9)&(all_apogee_labels[:,2]>-1.3))[0]]\n",
    "diff_f3 = all_apogee_diffs[np.where((all_apogee_labels[:,2]<-0.5)&(all_apogee_labels[:,2]>-0.9))[0]]\n",
    "diff_f4 = all_apogee_diffs[np.where((all_apogee_labels[:,2]<-0.3)&(all_apogee_labels[:,2]>-0.5))[0]]\n",
    "diff_f5 = all_apogee_diffs[np.where((all_apogee_labels[:,2]>-0.3))[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obtain a random sample of residuals from each bin\n",
    "Each sample has to be equal in size for proper statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(diff_t1)\n",
    "diff_t1 = diff_t1[0:1500]\n",
    "np.random.shuffle(diff_t2)\n",
    "diff_t2 = diff_t2[0:1500]\n",
    "np.random.shuffle(diff_t3)\n",
    "diff_t3 = diff_t3[0:1500]\n",
    "np.random.shuffle(diff_t4)\n",
    "diff_t4 = diff_t4[0:1500]\n",
    "np.random.shuffle(diff_t5)\n",
    "diff_t5 = diff_t5[0:1500]\n",
    "\n",
    "np.random.shuffle(diff_l1)\n",
    "diff_l1 = diff_l1[0:1500]\n",
    "np.random.shuffle(diff_l2)\n",
    "diff_l2 = diff_l2[0:1500]\n",
    "np.random.shuffle(diff_l3)\n",
    "diff_l3 = diff_l3[0:1500]\n",
    "np.random.shuffle(diff_l4)\n",
    "diff_l4 = diff_l4[0:1500]\n",
    "np.random.shuffle(diff_l5)\n",
    "diff_l5 = diff_l5[0:1500]\n",
    "\n",
    "np.random.shuffle(diff_f1)\n",
    "diff_f1 = diff_f1[0:1500]\n",
    "np.random.shuffle(diff_f2)\n",
    "diff_f2 = diff_f2[0:1500]\n",
    "np.random.shuffle(diff_f3)\n",
    "diff_f3 = diff_f3[0:1500]\n",
    "np.random.shuffle(diff_f4)\n",
    "diff_f4 = diff_f4[0:1500]\n",
    "np.random.shuffle(diff_f5)\n",
    "diff_f5 = diff_f5[0:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate scatter in different regions, $\\delta_{js}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_diff_t1 = np.std(diff_t1, axis=0)[0]\n",
    "std_diff_t2 = np.std(diff_t2, axis=0)[0]\n",
    "std_diff_t3 = np.std(diff_t3, axis=0)[0]\n",
    "std_diff_t4 = np.std(diff_t4, axis=0)[0]\n",
    "std_diff_t5 = np.std(diff_t5, axis=0)[0]\n",
    "\n",
    "std_diff_l1 = np.std(diff_l1, axis=0)[1]\n",
    "std_diff_l2 = np.std(diff_l2, axis=0)[1]\n",
    "std_diff_l3 = np.std(diff_l3, axis=0)[1]\n",
    "std_diff_l4 = np.std(diff_l4, axis=0)[1]\n",
    "std_diff_l5 = np.std(diff_l5, axis=0)[1]\n",
    "\n",
    "std_diff_f1 = np.std(diff_f1, axis=0)[2]\n",
    "std_diff_f2 = np.std(diff_f2, axis=0)[2]\n",
    "std_diff_f3 = np.std(diff_f3, axis=0)[2]\n",
    "std_diff_f4 = np.std(diff_f4, axis=0)[2]\n",
    "std_diff_f5 = np.std(diff_f5, axis=0)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Theano Function that returns the Jacobian matrix\n",
    "The jacobian matrix is a matrix of the first order derivatives of the outputs with respect to the input. In our case, this will be a 3-dimensional matrix with dimensions: (num_labels, num_test_spectra, num_flux_values).\n",
    "\n",
    "Each spectrum will therefore have 3 vectors the length of the spectrum: one vector for each of the first order derivatives of the output labels with respect to each flux value (wavelength bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jac = theano.gradient.jacobian(denormalize(model.layers[-1].output).flatten(),wrt=model.layers[0].input)\n",
    "compute_jac = theano.function([model.layers[0].input],[jac],allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Jacobian Matrix\n",
    "\\begin{equation}\n",
    "\\frac{\\partial h_{j}(\\textbf{x},\\textbf{W})}{\\partial \\textbf{x}} =  (\\frac{\\partial h_{j}(\\textbf{x},\\textbf{W})}{\\partial x_{1}},...,\\frac{\\partial h_{j}(\\textbf{x},\\textbf{W})}{\\partial x_{n}})\n",
    "\\end{equation} \n",
    "\n",
    "j = 1,...,3\n",
    "\n",
    "n = 1,...,7214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jacobian_matrix = np.zeros((3,1,7214))\n",
    "for i in range(len(test_1_spectra)):\n",
    "    a = compute_jac(test_1_spectra[i:i+1])[0].reshape(3,1,7214)\n",
    "    if i ==0:\n",
    "        jacobian_matrix = a\n",
    "    else:\n",
    "        jacobian_matrix = np.column_stack((jacobian_matrix,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask extremely high values in the error spectra and nan values in jacobian.\n",
    "\n",
    "The high values in the error spectrum are associated - for the most part - with zero-values in the APOGEE spectra. Since these zero values are essentially ignored in the model (due to RELU-activation and maxpooling layers) they do not effect the output labels and therefore, the flux errors associated with these zero-values give an innaccurate assessment of the prediction errors. If you were to include these error fluxes, you would have massive uncertainties in some of the stars' output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_1_error_spectra[test_1_error_spectra > 5] = 0\n",
    "jacobian_matrix = np.nan_to_num(jacobian_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine first order derivatives with error spectra\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta_{j\\textbf{x}} = \\frac{\\partial h_{j}(\\textbf{x},\\textbf{W})}{\\partial \\textbf{x}} \\cdot \\Delta \\textbf{x}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_1_pred_errors = np.array((np.einsum('ij,ij->i', np.square(jacobian_matrix[0]), np.square(test_1_error_spectra)),np.einsum('ij,ij->i', np.square(jacobian_matrix[1]), np.square(test_1_error_spectra)),np.einsum('ij,ij->i', np.square(jacobian_matrix[2]), np.square(test_1_error_spectra)))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label names\n",
    "label_names = ['Teff  ','log(g)','[Fe/H]']\n",
    "units = ['K','cgs','dex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error due to error spectrum: \n",
      "\n",
      "Teff  :  13.513 K\n",
      "log(g):  0.033 cgs\n",
      "[Fe/H]:  0.012 dex\n"
     ]
    }
   ],
   "source": [
    "mean_err_sp = np.mean(np.sqrt(test_1_pred_errors), axis=0)\n",
    "print('Mean error due to error spectrum: \\n')\n",
    "for i, err in enumerate(mean_err_sp):\n",
    "      print(label_names[i]+':  '+\"{0:.3f}\".format(err)+' '+units[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the previous errors with scatter from the corresponding bins\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta h_{j} = \\sqrt{\\delta_{j\\textbf{x}}^{2}  + \\delta_{js}^{2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_1_total_err = np.zeros((len(test_1_pred),3))\n",
    "for i, label in enumerate(test_1_pred):\n",
    "    std_diff_temp = np.zeros((1,3))\n",
    "    if (label[0]<4000) & (label[0]>10):\n",
    "        std_diff_temp[0,0]=std_diff_t1\n",
    "    elif (label[0]<4500) & (label[0]>4000):\n",
    "        std_diff_temp[0,0]=std_diff_t2\n",
    "    elif (label[0]<4750) & (label[0]>4500):\n",
    "        std_diff_temp[0,0]=std_diff_t3\n",
    "    elif (label[0]<5250) & (label[0]>4750):\n",
    "        std_diff_temp[0,0]=std_diff_t4\n",
    "    elif (label[0]<10000) & (label[0]>5250):\n",
    "        std_diff_temp[0,0]=std_diff_t5\n",
    "        \n",
    "    if (label[1]<0.5) & (label[0]>-10):\n",
    "        std_diff_temp[0,1]=std_diff_l1\n",
    "    elif (label[1]<1.5) & (label[0]>0.5):\n",
    "        std_diff_temp[0,1]=std_diff_l2\n",
    "    elif (label[1]<2.5) & (label[0]>1.5):\n",
    "        std_diff_temp[0,1]=std_diff_l3\n",
    "    elif (label[1]<3.5) & (label[0]>2.5):\n",
    "        std_diff_temp[0,1]=std_diff_l4\n",
    "    elif (label[1]<100) & (label[0]>3.5):\n",
    "        std_diff_temp[0,1]=std_diff_l5\n",
    "    \n",
    "    if (label[2]<-1.3) & (label[0]>-10):\n",
    "        std_diff_temp[0,2]=std_diff_f1\n",
    "    elif (label[2]<-0.9) & (label[0]>-1.3):\n",
    "        std_diff_temp[0,2]=std_diff_f2\n",
    "    elif (label[2]<-0.5) & (label[0]>-0.9):\n",
    "        std_diff_temp[0,2]=std_diff_f3\n",
    "    elif (label[2]<-0.3) & (label[0]>-0.5):\n",
    "        std_diff_temp[0,2]=std_diff_f4\n",
    "    elif (label[2]<0.5) & (label[0]>-0.3):\n",
    "        std_diff_temp[0,2]=std_diff_f5\n",
    "    \n",
    "    test_1_total_err[i] = np.sqrt(test_1_pred_errors[i]+np.square(std_diff_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean total statistical errors: \n",
      "\n",
      "Teff  :  67.354 K\n",
      "log(g):  0.206 cgs\n",
      "[Fe/H]:  0.134 dex\n"
     ]
    }
   ],
   "source": [
    "mean_err_total = np.mean(test_1_total_err, axis=0)\n",
    "print('Mean total statistical errors: \\n')\n",
    "for i, err in enumerate(mean_err_total):\n",
    "      print(label_names[i]+':  '+\"{0:.3f}\".format(err)+' '+units[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
