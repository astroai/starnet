{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain test data\n",
    "\n",
    "## This notebook takes you through the steps of how to preprocess a high S/N and low S/N test set\n",
    "## downloading apStar_combined_main.h5 is necessary before beginning this procedure\n",
    "### download link: [url]\n",
    "## required packages:\n",
    "### - vos\n",
    "### - numpy\n",
    "### - h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download apStar visits data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename='apStar_visits_main.h5'\n",
    "vclient = vos.Client()\n",
    "vclient.copy('vos:starnet/public/'+filename, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain training data and separate out a High S/N Test set\n",
    "#### apStar_combined_main.h5 is a data file created by pulling apStar combined spectra from the APOGEE v603.fits file\n",
    "#### instructions on dealing with apogee data can be found here: https://github.com/jobovy/apogee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'apStar_combined_main.h5'\n",
    "path = filename\n",
    "f = h5py.File(path,\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Dataset keys in file: \\n')\n",
    "for i in f.keys(): print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for the testing of StarNet, it is necessary to obtain the spectra, error spectra, combined S/N, and labels, but we need to make eliminations to the test set to obtain the labels of highest validity to compare with, so we will first include the$APOGEE\\_IDs$, $S/N$ of the combined spectra, spectra, error spectra, $T_{\\mathrm{eff}}$,$\\log(g)$, $[Fe/H]$, $V_{scatter}$, $STARFLAGs$, and $ASPCAPFLAGs$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ap_id = f['IDs'][:,0]\n",
    "\n",
    "spectra = f['spectrum'][:]\n",
    "error_spectra = f['error_spectrum'][:]\n",
    "combined_snr = f['stacked_snr'][:]\n",
    "starflag = f['star_flag'][:]\n",
    "aspcapflag = f['aspcap_flag'][:]\n",
    "teff = f['TEFF'][:]\n",
    "logg = f['LOGG'][:]\n",
    "fe_h = f['FE_H'][:]\n",
    "vscatter = f['VSCATTER'][:]\n",
    "\n",
    "print('Obtainined spectra and data for '+str(len(list(set(list(ap_id)))))+' stars.')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a file that contains the mean and std for $T_{\\mathrm{eff}}$,$\\log(g)$,and  $[Fe/H]$ in order to normalize labels during training and testing\n",
    "#### ignore values equal to -9999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = np.array([np.mean(teff[teff!=-9999.]),np.mean(logg[logg!=-9999.]),np.mean(fe_h[fe_h!=-9999.])])\n",
    "std = np.array([np.std(teff[teff!=-9999.]),np.std(logg[logg!=-9999.]),np.std(fe_h[fe_h!=-9999.])])\n",
    "mean_and_std = np.row_stack((mean,std))\n",
    "np.save('mean_and_std', mean_and_std)\n",
    "\n",
    "print('mean_and_std.npy saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate out a dataset with good labels\n",
    "## Default initial restrictions:\n",
    "### - $STARFLAGs$ = 0\n",
    "### -  $ASPCAPFLAGs$ = 0\n",
    "### - 4000K < $T_{\\mathrm{eff}}$ < 5500K\n",
    "### - -3.0 < $[Fe/H]$\n",
    "### - $\\log(g)$ != -9999. (value defined by ASPCAP when no ASPCAP labels are given)\n",
    "### - $V_{scatter}$ < 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teff_min = 4000.\n",
    "teff_max = 5500.\n",
    "vscatter_max = 1.\n",
    "fe_h_min = -3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices, cols = np.where((aspcapflag[:]==0.)&(starflag[:]==0.)&(vscatter[:]<vscatter_max)&(fe_h[:]>fe_h_min)&(teff[:]>teff_min)&(teff[:]<teff_max)&(logg[:]!=-9999.).reshape(len(ap_id),1))\n",
    "\n",
    "ap_id = ap_id[indices]\n",
    "spectra = spectra[indices]\n",
    "error_spectra = error_spectra[indices]\n",
    "teff = teff[indices]\n",
    "logg = logg[indices]\n",
    "fe_h = fe_h[indices]\n",
    "combined_snr = combined_snr[indices]\n",
    "\n",
    "print(str(len(list(set(list(ap_id)))))+' stars remain.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load $APOGEE\\_IDs$ for High S/N test set obtained in $1\\_Preprocessing\\_of\\_Training\\_Data$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_snr_test_ap_ids = np.load('high_snr_test_apids.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate data for High S/N test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = [i for i, item in enumerate(high_snr_test_ap_ids) if item in ap_id]\n",
    "\n",
    "high_snr_ap_id = ap_id[indices]\n",
    "high_snr_spectra = spectra[indices]\n",
    "high_snr_error_spectra = error_spectra[indices]\n",
    "high_snr_teff = teff[indices]\n",
    "high_snr_logg = logg[indices]\n",
    "high_snr_fe_h = fe_h[indices]\n",
    "high_snr_combined_snr = combined_snr[indices]\n",
    "\n",
    "print('High S/N test set includes '+str(len(high_snr_ap_id))+' combined spectra')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Normalize spectra:\n",
    "#### 1. separate into three chips\n",
    "#### 2. divide by median value in each chip\n",
    "#### 3. recombine into vector of 7214 flux values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define edges of detectors\n",
    "blue_chip_begin = 322\n",
    "blue_chip_end = 3242\n",
    "green_chip_begin = 3648\n",
    "green_chip_end = 6048   \n",
    "red_chip_begin = 6412\n",
    "red_chip_end = 8306 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate spectra into chips\n",
    "\n",
    "blue_sp = high_snr_spectra[:,blue_chip_begin:blue_chip_end]\n",
    "green_sp = high_snr_spectra[:,green_chip_begin:green_chip_end]\n",
    "red_sp = high_snr_spectra[:,red_chip_begin:red_chip_end]\n",
    "\n",
    "#Normalize spectra by chips\n",
    "\n",
    "blue_sp_med = np.median(blue_sp, axis=1)\n",
    "green_sp_med = np.median(green_sp, axis=1)\n",
    "red_sp_med = np.median(red_sp, axis=1)\n",
    "\n",
    "blue_sp = (blue_sp.T/blue_sp_med).T\n",
    "green_sp = (green_sp.T/green_sp_med).T\n",
    "red_sp = (red_sp.T/red_sp_med).T  \n",
    "\n",
    "# Recombine spectra\n",
    "\n",
    "high_snr_spectra = np.column_stack((blue_sp,green_sp,red_sp))\n",
    "\n",
    "print('High S/N spectra dataset now contains '+str(high_snr_spectra.shape[0])+' spectra, each with '+str(high_snr_spectra.shape[1])+' wavelength bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error spectra also must be normalized with the same median values for error propagaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate error spectra into chips\n",
    "\n",
    "blue_sp = high_snr_error_spectra[:,blue_chip_begin:blue_chip_end]\n",
    "green_sp = high_snr_error_spectra[:,green_chip_begin:green_chip_end]\n",
    "red_sp = high_snr_error_spectra[:,red_chip_begin:red_chip_end]\n",
    "\n",
    "# Normalize error spectra by chips\n",
    "\n",
    "blue_sp = (blue_sp.T/blue_sp_med).T\n",
    "green_sp = (green_sp.T/green_sp_med).T\n",
    "red_sp = (red_sp.T/red_sp_med).T\n",
    "\n",
    "# Recombine error spectra\n",
    "\n",
    "high_snr_error_spectra = np.column_stack((blue_sp,green_sp,red_sp))\n",
    "\n",
    "print('High S/N error spectra dataset now contains '+str(high_snr_error_spectra.shape[0])+' error spectra, each with '+str(high_snr_error_spectra.shape[1])+' wavelength bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save new High S/N test data file with APOGEE IDs, spectra, error spectra, combined S/N and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savename = 'high_snr_test_data.h5'\n",
    "path = savename\n",
    "# if path already exist, you must remove it first using os.remove(path) \n",
    "os.remove(path)\n",
    "dt = h5py.special_dtype(vlen=bytes)\n",
    "with h5py.File(path, \"a\") as f:\n",
    "     \n",
    "    spectra_ds = f.create_dataset('spectra', high_snr_spectra.shape, dtype=\"f\")\n",
    "    error_spectra_ds = f.create_dataset('error_spectra', high_snr_error_spectra.shape, dtype=\"f\")\n",
    "    teff_ds = f.create_dataset('TEFF', high_snr_teff.shape, dtype=\"f\")\n",
    "    logg_ds = f.create_dataset('LOGG', high_snr_logg.shape, dtype=\"f\")\n",
    "    fe_h_ds = f.create_dataset('FE_H', high_snr_fe_h.shape, dtype=\"f\")\n",
    "    combined_snr_ds = f.create_dataset('combined_snr', high_snr_combined_snr.shape, dtype=\"f\")\n",
    "    ap_id_ds = f.create_dataset('Ap_IDs', high_snr_ap_id.shape, dtype=\"S18\")\n",
    "    \n",
    "    spectra_ds[:] = high_snr_spectra\n",
    "    error_spectra_ds[:] = high_snr_error_spectra\n",
    "    teff_ds[:] = high_snr_teff\n",
    "    logg_ds[:] = high_snr_logg\n",
    "    fe_h_ds[:] = high_snr_fe_h\n",
    "    combined_snr_ds[:] = high_snr_combined_snr\n",
    "    ap_id_ds[:] = high_snr_ap_id.tolist()\n",
    "    \n",
    "print(savename+' has been saved as the High S/N test set to be used in 4_Test_Model.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now create Low S/N test set\n",
    "## default additional restrictions:\n",
    "### - combined S/N < 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snr_max = 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices, cols = np.where((combined_snr[:]<snr_max).reshape(len(ap_id),1))\n",
    "\n",
    "low_snr_ap_id = ap_id[indices]\n",
    "low_snr_spectra = spectra[indices]\n",
    "low_snr_error_spectra = error_spectra[indices]\n",
    "low_snr_teff = teff[indices]\n",
    "low_snr_logg = logg[indices]\n",
    "low_snr_fe_h = fe_h[indices]\n",
    "low_snr_combined_snr = combined_snr[indices]\n",
    "\n",
    "print('Low S/N test set includes '+str(len(low_snr_ap_id))+' combined spectra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Normalize spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define edges of detectors\n",
    "blue_chip_begin = 322\n",
    "blue_chip_end = 3242\n",
    "green_chip_begin = 3648\n",
    "green_chip_end = 6048   \n",
    "red_chip_begin = 6412\n",
    "red_chip_end = 8306 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate spectra into chips\n",
    "\n",
    "blue_sp = low_snr_spectra[:,blue_chip_begin:blue_chip_end]\n",
    "green_sp = low_snr_spectra[:,green_chip_begin:green_chip_end]\n",
    "red_sp = low_snr_spectra[:,red_chip_begin:red_chip_end]\n",
    "\n",
    "#Normalize spectra by chips\n",
    "\n",
    "blue_sp_med = np.median(blue_sp, axis=1)\n",
    "green_sp_med = np.median(green_sp, axis=1)\n",
    "red_sp_med = np.median(red_sp, axis=1)\n",
    "\n",
    "blue_sp = (blue_sp.T/blue_sp_med).T\n",
    "green_sp = (green_sp.T/green_sp_med).T\n",
    "red_sp = (red_sp.T/red_sp_med).T  \n",
    "\n",
    "# Recombine spectra\n",
    "\n",
    "low_snr_spectra = np.column_stack((blue_sp,green_sp,red_sp))\n",
    "print('Low S/N spectra dataset now contains '+str(low_snr_spectra.shape[0])+' spectra, each with '+str(low_snr_spectra.shape[1])+' wavelength bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Normalize error spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate error spectra into chips\n",
    "\n",
    "blue_sp = low_snr_error_spectra[:,blue_chip_begin:blue_chip_end]\n",
    "green_sp = low_snr_error_spectra[:,green_chip_begin:green_chip_end]\n",
    "red_sp = low_snr_error_spectra[:,red_chip_begin:red_chip_end]\n",
    "\n",
    "# Normalize error spectra by chips\n",
    "\n",
    "blue_sp = (blue_sp.T/blue_sp_med).T\n",
    "green_sp = (green_sp.T/green_sp_med).T\n",
    "red_sp = (red_sp.T/red_sp_med).T\n",
    "\n",
    "# Recombine error spectra\n",
    "\n",
    "low_snr_error_spectra = np.column_stack((blue_sp,green_sp,red_sp))\n",
    "\n",
    "print('Low S/N error spectra dataset now contains '+str(low_snr_error_spectra.shape[0])+' error spectra, each with '+str(low_snr_error_spectra.shape[1])+' wavelength bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save new Low S/N test data file with APOGEE IDs, spectra, error spectra, combined S/N and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savename = 'low_snr_test_data.h5'\n",
    "path = savename\n",
    "# if path already exist, you must remove it first using os.remove(path) \n",
    "os.remove(path)\n",
    "dt = h5py.special_dtype(vlen=bytes)\n",
    "with h5py.File(path, \"a\") as f:\n",
    "     \n",
    "    spectra_ds = f.create_dataset('spectra', low_snr_spectra.shape, dtype=\"f\")\n",
    "    error_spectra_ds = f.create_dataset('error_spectra', low_snr_error_spectra.shape, dtype=\"f\")\n",
    "    teff_ds = f.create_dataset('TEFF', low_snr_teff.shape, dtype=\"f\")\n",
    "    logg_ds = f.create_dataset('LOGG', low_snr_logg.shape, dtype=\"f\")\n",
    "    fe_h_ds = f.create_dataset('FE_H', low_snr_fe_h.shape, dtype=\"f\")\n",
    "    combined_snr_ds = f.create_dataset('combined_snr', low_snr_combined_snr.shape, dtype=\"f\")\n",
    "    ap_id_ds = f.create_dataset('Ap_IDs', low_snr_ap_id.shape, dtype=\"S18\")\n",
    "    \n",
    "    spectra_ds[:] = low_snr_spectra\n",
    "    error_spectra_ds[:] = low_snr_error_spectra\n",
    "    teff_ds[:] = low_snr_teff\n",
    "    logg_ds[:] = low_snr_logg\n",
    "    fe_h_ds[:] = low_snr_fe_h\n",
    "    combined_snr_ds[:] = low_snr_combined_snr\n",
    "    ap_id_ds[:] = low_snr_ap_id.tolist()\n",
    "\n",
    "print(savename+' has been saved as the Low S/N test set to be used in 4_Test_Model.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
