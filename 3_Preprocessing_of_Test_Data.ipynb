{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain test data\n",
    "\n",
    "This notebook takes you through the steps of how to preprocess a high S/N and low S/N test set\n",
    "\n",
    "## required packages:\n",
    "- numpy\n",
    "- h5py\n",
    "\n",
    "## required data files:\n",
    "- apStar_combined_main.h5\n",
    "  - can be downloaded in $1\\_Download\\_Data.ipynb$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load apStar_combined_main.h5 \n",
    "a file that contains combined spectra along with APOGEE data associated with each star. File can be downloaded in $1\\_Download\\_Data.ipynb$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = 'apStar_combined_main.h5'\n",
    "f = h5py.File(filename,\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset keys in file: \n",
      "\n",
      "0_H\n",
      "0_H_ERR\n",
      "ALPHA_M\n",
      "AL_H\n",
      "AL_H_ERR\n",
      "CA_H\n",
      "CA_H_ERR\n",
      "C_H\n",
      "C_H_ERR\n",
      "FE_H\n",
      "FE_H_ERR\n",
      "IDs\n",
      "K_H\n",
      "K_H_ERR\n",
      "LOGG\n",
      "LOGG_ERR\n",
      "MG_H\n",
      "MG_H_ERR\n",
      "MN_H\n",
      "MN_H_ERR\n",
      "NA_H\n",
      "NA_H_ERR\n",
      "NI_H\n",
      "NI_H_ERR\n",
      "N_H\n",
      "N_H_ERR\n",
      "SI_H\n",
      "SI_H_ERR\n",
      "S_H\n",
      "S_H_ERR\n",
      "TEFF\n",
      "TEFF_ERR\n",
      "TI_H\n",
      "TI_H_ERR\n",
      "VRAD\n",
      "VRAD_ERR\n",
      "VSCATTER\n",
      "V_H\n",
      "V_H_ERR\n",
      "aspcap_flag\n",
      "error_spectrum\n",
      "num_visits\n",
      "spectrum\n",
      "stacked_snr\n",
      "star_flag\n",
      "targ1_flag\n",
      "targ2_flag\n"
     ]
    }
   ],
   "source": [
    "print('Dataset keys in file: \\n')\n",
    "for i in f.keys(): print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the testing of StarNet, it is necessary to obtain the spectra, error spectra, combined S/N, and labels, but we need to make eliminations to the test set to obtain the labels of highest validity to compare with, so we will first include the $APOGEE\\_IDs$, the spectra, error spectra, the $S/N$ of the combined spectra, $T_{\\mathrm{eff}}$, $\\log(g)$, $[Fe/H]$, $V_{scatter}$, $STARFLAGs$, and $ASPCAPFLAGs$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtainined spectra and data for 142333 stars.\n"
     ]
    }
   ],
   "source": [
    "ap_id = f['IDs'][:,0]\n",
    "\n",
    "spectra = f['spectrum'][:]\n",
    "error_spectra = f['error_spectrum'][:]\n",
    "combined_snr = f['stacked_snr'][:]\n",
    "starflag = f['star_flag'][:]\n",
    "aspcapflag = f['aspcap_flag'][:]\n",
    "teff = f['TEFF'][:]\n",
    "logg = f['LOGG'][:]\n",
    "fe_h = f['FE_H'][:]\n",
    "vscatter = f['VSCATTER'][:]\n",
    "\n",
    "print('Obtainined spectra and data for '+str(len(list(set(list(ap_id)))))+' stars.')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a file that contains the mean and std for $T_{\\mathrm{eff}}$, $\\log(g)$, and  $[Fe/H]$ in order to normalize labels during training and testing\n",
    "ignore values equal to -9999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_and_std.npy saved\n"
     ]
    }
   ],
   "source": [
    "mean = np.array([np.mean(teff[teff!=-9999.]),np.mean(logg[logg!=-9999.]),np.mean(fe_h[fe_h!=-9999.])])\n",
    "std = np.array([np.std(teff[teff!=-9999.]),np.std(logg[logg!=-9999.]),np.std(fe_h[fe_h!=-9999.])])\n",
    "mean_and_std = np.row_stack((mean,std))\n",
    "np.save('mean_and_std', mean_and_std)\n",
    "\n",
    "print('mean_and_std.npy saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate out a dataset with good labels\n",
    "### Default initial restrictions:\n",
    "- $STARFLAGs$ = 0\n",
    "- $ASPCAPFLAGs$ = 0\n",
    "- 4000K < $T_{\\mathrm{eff}}$ < 5500K\n",
    "- -3.0 < $[Fe/H]$\n",
    "- $\\log(g)$ $\\neq$ -9999. (value defined by ASPCAP when no ASPCAP labels are given)\n",
    "- $V_{scatter}$ < 1.0 km/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teff_min = 4000.\n",
    "teff_max = 5500.\n",
    "vscatter_max = 1.\n",
    "fe_h_min = -3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34484 stars remain.\n"
     ]
    }
   ],
   "source": [
    "indices, cols = np.where((aspcapflag[:]==0.)&(starflag[:]==0.)&(vscatter[:]<vscatter_max)&(fe_h[:]>fe_h_min)&(teff[:]>teff_min)&(teff[:]<teff_max)&(logg[:]!=-9999.).reshape(len(ap_id),1))\n",
    "\n",
    "ap_id = ap_id[indices]\n",
    "spectra = spectra[indices]\n",
    "error_spectra = error_spectra[indices]\n",
    "teff = teff[indices]\n",
    "logg = logg[indices]\n",
    "fe_h = fe_h[indices]\n",
    "combined_snr = combined_snr[indices]\n",
    "\n",
    "print(str(len(list(set(list(ap_id)))))+' stars remain.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load high_snr_test_apids.npy \n",
    "A file that contains the APOGEE IDs for High S/N spectra that will be processed into the High S/N test set (file can be obtained in $2\\_Preprocessing\\_of\\_Training\\_Data.ipynb$ or downloaded from $1\\_Download\\_Data.ipynb$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_snr_test_ap_ids = np.load('high_snr_test_apids.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate data for High S/N test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High S/N test set includes 2780 combined spectra\n"
     ]
    }
   ],
   "source": [
    "indices = [i for i, item in enumerate(high_snr_test_ap_ids) if item in ap_id]\n",
    "\n",
    "high_snr_ap_id = ap_id[indices]\n",
    "high_snr_spectra = spectra[indices]\n",
    "high_snr_error_spectra = error_spectra[indices]\n",
    "high_snr_teff = teff[indices]\n",
    "high_snr_logg = logg[indices]\n",
    "high_snr_fe_h = fe_h[indices]\n",
    "high_snr_combined_snr = combined_snr[indices]\n",
    "\n",
    "print('High S/N test set includes '+str(len(high_snr_ap_id))+' combined spectra')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Normalize spectra:\n",
    "### 1. separate into three chips\n",
    "### 2. divide by median value in each chip\n",
    "### 3. recombine each spectrum into a vector of 7214 flux values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define edges of detectors\n",
    "blue_chip_begin = 322\n",
    "blue_chip_end = 3242\n",
    "green_chip_begin = 3648\n",
    "green_chip_end = 6048   \n",
    "red_chip_begin = 6412\n",
    "red_chip_end = 8306 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High S/N spectra dataset now contains 2780 spectra, each with 7214 wavelength bins\n"
     ]
    }
   ],
   "source": [
    "# Separate spectra into chips\n",
    "\n",
    "blue_sp = high_snr_spectra[:,blue_chip_begin:blue_chip_end]\n",
    "green_sp = high_snr_spectra[:,green_chip_begin:green_chip_end]\n",
    "red_sp = high_snr_spectra[:,red_chip_begin:red_chip_end]\n",
    "\n",
    "#Normalize spectra by chips\n",
    "\n",
    "blue_sp_med = np.median(blue_sp, axis=1)\n",
    "green_sp_med = np.median(green_sp, axis=1)\n",
    "red_sp_med = np.median(red_sp, axis=1)\n",
    "\n",
    "blue_sp = (blue_sp.T/blue_sp_med).T\n",
    "green_sp = (green_sp.T/green_sp_med).T\n",
    "red_sp = (red_sp.T/red_sp_med).T  \n",
    "\n",
    "# Recombine spectra\n",
    "\n",
    "high_snr_spectra = np.column_stack((blue_sp,green_sp,red_sp))\n",
    "\n",
    "print('High S/N spectra dataset now contains '+str(high_snr_spectra.shape[0])+' spectra, each with '+str(high_snr_spectra.shape[1])+' wavelength bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error spectra also must be normalized with the same median values for error propagaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High S/N error spectra dataset now contains 2780 error spectra, each with 7214 wavelength bins\n"
     ]
    }
   ],
   "source": [
    "# Separate error spectra into chips\n",
    "\n",
    "blue_sp = high_snr_error_spectra[:,blue_chip_begin:blue_chip_end]\n",
    "green_sp = high_snr_error_spectra[:,green_chip_begin:green_chip_end]\n",
    "red_sp = high_snr_error_spectra[:,red_chip_begin:red_chip_end]\n",
    "\n",
    "# Normalize error spectra by chips\n",
    "\n",
    "blue_sp = (blue_sp.T/blue_sp_med).T\n",
    "green_sp = (green_sp.T/green_sp_med).T\n",
    "red_sp = (red_sp.T/red_sp_med).T\n",
    "\n",
    "# Recombine error spectra\n",
    "\n",
    "high_snr_error_spectra = np.column_stack((blue_sp,green_sp,red_sp))\n",
    "\n",
    "print('High S/N error spectra dataset now contains '+str(high_snr_error_spectra.shape[0])+' error spectra, each with '+str(high_snr_error_spectra.shape[1])+' wavelength bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save new High S/N test data file with APOGEE IDs, spectra, error spectra, combined S/N and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high_snr_test_data.h5 has been saved as the High S/N test set to be used in 5_Test_Model.ipynb\n"
     ]
    }
   ],
   "source": [
    "savename = 'high_snr_test_data.h5'\n",
    "# if path already exist, you must remove it first using os.remove(savename) \n",
    "#os.remove(savename)\n",
    "dt = h5py.special_dtype(vlen=bytes)\n",
    "with h5py.File(savename, \"a\") as f:\n",
    "     \n",
    "    spectra_ds = f.create_dataset('spectra', high_snr_spectra.shape, dtype=\"f\")\n",
    "    error_spectra_ds = f.create_dataset('error_spectra', high_snr_error_spectra.shape, dtype=\"f\")\n",
    "    teff_ds = f.create_dataset('TEFF', high_snr_teff.shape, dtype=\"f\")\n",
    "    logg_ds = f.create_dataset('LOGG', high_snr_logg.shape, dtype=\"f\")\n",
    "    fe_h_ds = f.create_dataset('FE_H', high_snr_fe_h.shape, dtype=\"f\")\n",
    "    combined_snr_ds = f.create_dataset('combined_snr', high_snr_combined_snr.shape, dtype=\"f\")\n",
    "    ap_id_ds = f.create_dataset('Ap_IDs', high_snr_ap_id.shape, dtype=\"S18\")\n",
    "    \n",
    "    spectra_ds[:] = high_snr_spectra\n",
    "    error_spectra_ds[:] = high_snr_error_spectra\n",
    "    teff_ds[:] = high_snr_teff\n",
    "    logg_ds[:] = high_snr_logg\n",
    "    fe_h_ds[:] = high_snr_fe_h\n",
    "    combined_snr_ds[:] = high_snr_combined_snr\n",
    "    ap_id_ds[:] = high_snr_ap_id.tolist()\n",
    "    \n",
    "print(savename+' has been saved as the High S/N test set to be used in 5_Test_Model.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now create Low S/N test set\n",
    "### default additional restrictions:\n",
    "- combined S/N < 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snr_max = 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low S/N test set includes 17506 combined spectra\n"
     ]
    }
   ],
   "source": [
    "indices, cols = np.where((combined_snr[:]<snr_max).reshape(len(ap_id),1))\n",
    "\n",
    "low_snr_ap_id = ap_id[indices]\n",
    "low_snr_spectra = spectra[indices]\n",
    "low_snr_error_spectra = error_spectra[indices]\n",
    "low_snr_teff = teff[indices]\n",
    "low_snr_logg = logg[indices]\n",
    "low_snr_fe_h = fe_h[indices]\n",
    "low_snr_combined_snr = combined_snr[indices]\n",
    "\n",
    "print('Low S/N test set includes '+str(len(low_snr_ap_id))+' combined spectra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Normalize spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define edges of detectors\n",
    "blue_chip_begin = 322\n",
    "blue_chip_end = 3242\n",
    "green_chip_begin = 3648\n",
    "green_chip_end = 6048   \n",
    "red_chip_begin = 6412\n",
    "red_chip_end = 8306 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low S/N spectra dataset now contains 17506 spectra, each with 7214 wavelength bins\n"
     ]
    }
   ],
   "source": [
    "# Separate spectra into chips\n",
    "\n",
    "blue_sp = low_snr_spectra[:,blue_chip_begin:blue_chip_end]\n",
    "green_sp = low_snr_spectra[:,green_chip_begin:green_chip_end]\n",
    "red_sp = low_snr_spectra[:,red_chip_begin:red_chip_end]\n",
    "\n",
    "#Normalize spectra by chips\n",
    "\n",
    "blue_sp_med = np.median(blue_sp, axis=1)\n",
    "green_sp_med = np.median(green_sp, axis=1)\n",
    "red_sp_med = np.median(red_sp, axis=1)\n",
    "\n",
    "blue_sp = (blue_sp.T/blue_sp_med).T\n",
    "green_sp = (green_sp.T/green_sp_med).T\n",
    "red_sp = (red_sp.T/red_sp_med).T  \n",
    "\n",
    "# Recombine spectra\n",
    "\n",
    "low_snr_spectra = np.column_stack((blue_sp,green_sp,red_sp))\n",
    "print('Low S/N spectra dataset now contains '+str(low_snr_spectra.shape[0])+' spectra, each with '+str(low_snr_spectra.shape[1])+' wavelength bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Normalize error spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low S/N error spectra dataset now contains 17506 error spectra, each with 7214 wavelength bins\n"
     ]
    }
   ],
   "source": [
    "# Separate error spectra into chips\n",
    "\n",
    "blue_sp = low_snr_error_spectra[:,blue_chip_begin:blue_chip_end]\n",
    "green_sp = low_snr_error_spectra[:,green_chip_begin:green_chip_end]\n",
    "red_sp = low_snr_error_spectra[:,red_chip_begin:red_chip_end]\n",
    "\n",
    "# Normalize error spectra by chips\n",
    "\n",
    "blue_sp = (blue_sp.T/blue_sp_med).T\n",
    "green_sp = (green_sp.T/green_sp_med).T\n",
    "red_sp = (red_sp.T/red_sp_med).T\n",
    "\n",
    "# Recombine error spectra\n",
    "\n",
    "low_snr_error_spectra = np.column_stack((blue_sp,green_sp,red_sp))\n",
    "\n",
    "print('Low S/N error spectra dataset now contains '+str(low_snr_error_spectra.shape[0])+' error spectra, each with '+str(low_snr_error_spectra.shape[1])+' wavelength bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save new Low S/N test data file with APOGEE IDs, spectra, error spectra, combined S/N and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low_snr_test_data.h5 has been saved as the Low S/N test set to be used in 5_Test_Model.ipynb\n"
     ]
    }
   ],
   "source": [
    "savename = 'low_snr_test_data.h5'\n",
    "# if path already exist, you must remove it first using os.remove(savename) \n",
    "#os.remove(savename)\n",
    "dt = h5py.special_dtype(vlen=bytes)\n",
    "with h5py.File(savename, \"a\") as f:\n",
    "     \n",
    "    spectra_ds = f.create_dataset('spectra', low_snr_spectra.shape, dtype=\"f\")\n",
    "    error_spectra_ds = f.create_dataset('error_spectra', low_snr_error_spectra.shape, dtype=\"f\")\n",
    "    teff_ds = f.create_dataset('TEFF', low_snr_teff.shape, dtype=\"f\")\n",
    "    logg_ds = f.create_dataset('LOGG', low_snr_logg.shape, dtype=\"f\")\n",
    "    fe_h_ds = f.create_dataset('FE_H', low_snr_fe_h.shape, dtype=\"f\")\n",
    "    combined_snr_ds = f.create_dataset('combined_snr', low_snr_combined_snr.shape, dtype=\"f\")\n",
    "    ap_id_ds = f.create_dataset('Ap_IDs', low_snr_ap_id.shape, dtype=\"S18\")\n",
    "    \n",
    "    spectra_ds[:] = low_snr_spectra\n",
    "    error_spectra_ds[:] = low_snr_error_spectra\n",
    "    teff_ds[:] = low_snr_teff\n",
    "    logg_ds[:] = low_snr_logg\n",
    "    fe_h_ds[:] = low_snr_fe_h\n",
    "    combined_snr_ds[:] = low_snr_combined_snr\n",
    "    ap_id_ds[:] = low_snr_ap_id.tolist()\n",
    "\n",
    "print(savename+' has been saved as the Low S/N test set to be used in 5_Test_Model.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
